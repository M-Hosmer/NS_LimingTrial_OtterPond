---
title: "NS_LimingTrial_OtterPond"
output: html_document
date: "2023-08-31"
---

```{R, results='hide', fig.keep='all', message=FALSE}
options(warn = -1)
library(reticulate)
#library(kableExtra)
library(knitr)
library(phyloseq)
library(microbiome)
library(philr)
library(ape)
library(tidyr)
library(vegan)
library(randomcoloR)
library(gridExtra)
library(metacoder)
library("data.table")
library("plyr")
library(DESeq2)
library(ALDEx2) 
library(Maaslin2)
library(tidyverse)
library(readxl)
library(glue)
library(ggtext)
library(microbiomeutilities)
library(ggpubr)
conda_python(envname = 'r-reticulate', conda = "auto")

```

```{python, results='hide', fig.keep='all', message=FALSE}
import pandas as pd
import math
import matplotlib.pyplot as plt
from matplotlib.patches import Ellipse
from matplotlib.patches import Patch
import matplotlib.transforms as transforms
from scipy.stats import ttest_ind
import matplotlib as mpl
import matplotlib.cm as cm
from matplotlib.lines import Line2D
from matplotlib.offsetbox import AnchoredText
from skbio.diversity import get_alpha_diversity_metrics, get_beta_diversity_metrics, alpha_diversity, beta_diversity
from skbio import read
from skbio.tree import TreeNode
import numpy as np
from scipy.stats import ttest_ind
from deicode.preprocessing import rclr
from skbio.stats.composition import clr
from scipy.spatial import distance
from skbio.stats import ordination
from sklearn import preprocessing
#from sklearn.metrics import plot_roc_curve
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix
from Bio import Phylo
import random
import pickle
from ete3 import Tree
#from bioinfokit.analys import stat

folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"



def confidence_ellipse(x, y, ax, n_std=2.0, facecolor='none', **kwargs):
    x = np.array(x)
    y = np.array(y)
    if x.size != y.size:
        raise ValueError("x and y must be the same size")
    cov = np.cov(x, y)
    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])
    # Using a special case to obtain the eigenvalues of this
    # two-dimensionl dataset.
    ell_radius_x = np.sqrt(1 + pearson)
    ell_radius_y = np.sqrt(1 - pearson)
    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,
                      facecolor=facecolor, **kwargs)
    # Calculating the stdandard deviation of x from
    # the squareroot of the variance and multiplying
    # with the given number of standard deviations.
    scale_x = np.sqrt(cov[0, 0]) * n_std
    mean_x = np.mean(x)
    # calculating the stdandard deviation of y ...
    scale_y = np.sqrt(cov[1, 1]) * n_std
    mean_y = np.mean(y)
    transf = transforms.Affine2D() \
        .rotate_deg(45) \
        .scale(scale_x, scale_y) \
        .translate(mean_x, mean_y)
    ellipse.set_transform(transf + ax.transData)
    return ax.add_patch(ellipse)

saving_figures = False
```

Draw tree:
```{python}
def draw_tree(tree, orient_tree='horizontal', vert_orient='down', axes=None, label_func=str, span=355, plot_labels=True, end_same=True, fs=10):
    # Arrays that store lines for the plot of clades
    horizontal_linecollections = []
    vertical_linecollections = []
    def get_x_positions(tree):
        """Create a mapping of each clade to its horizontal position.
        Dict of {clade: x-coord}
        """
        depths = tree.depths()
        # If there are no branch lengths, assume unit branch lengths
        if not max(depths.values()):
            depths = tree.depths(unit_branch_lengths=True)
        return depths
    def format_branch_label(clade):
                return None
    def get_y_positions(tree):
        """Create a mapping of each clade to its vertical position.
        Dict of {clade: y-coord}.
        Coordinates are negative, and integers for tips.
        """
        maxheight = tree.count_terminals()
        # Rows are defined by the tips
        heights = {tip: maxheight - i for i, tip in enumerate(reversed(tree.get_terminals()))}
        # Internal nodes: place at midpoint of children
        def calc_row(clade):
            for subclade in clade:
                if subclade not in heights:
                    calc_row(subclade)
            # Closure over heights
            heights[clade] = (
                heights[clade.clades[0]] + heights[clade.clades[-1]]
            ) / 2.0
        if tree.root.clades:
            calc_row(tree.root)
        return heights
    x_posns = get_x_positions(tree)
    y_posns = get_y_positions(tree)
    if axes is None:
        fig = plt.figure()
        if orient_tree == 'circular':
            axes = fig.add_subplot(1, 1, 1, orientation='polar')
        else:
            axes = fig.add_subplot(1, 1, 1)
    elif not isinstance(axes, plt.matplotlib.axes.Axes):
        raise ValueError("Invalid argument for axes: %s" % axes)
    leaves = [['Label', 'x loc', 'y loc', 'rotation', 'va', 'ha']]
    def draw_clade_lines(orientation="horizontal",y_here=0,x_start=0,x_here=0,y_bot=0,y_top=0,color="black",lw=".1", ls='-'):
        """Create a line.
        Graphical formatting of the lines representing clades in the plot can be
        customized by altering this function.
        """
        if orientation == "horizontal":
            axes.hlines(y_here, x_start, x_here, color=color, lw=lw, linestyle=ls)
        elif orientation == "vertical":
            axes.vlines(x_here, y_bot, y_top, color=color, linestyle=ls)
    def draw_clade(clade, x_start, color, lw, orient_tree='horizontal', vert_orient='up'):
        """Recursively draw a tree, down from the given clade."""
        x_here = x_posns[clade]
        y_here = y_posns[clade]
        xmax = max(x_posns.values())+max(x_posns.values())/30
        # phyloXML-only graphics annotations
        if hasattr(clade, "color") and clade.color is not None:
            color = clade.color.to_hex()
        if hasattr(clade, "width") and clade.width is not None:
            lw = clade.width * plt.rcParams["lines.linewidth"]
        if orient_tree == 'horizontal':
            # Draw a horizontal line from start to here
            draw_clade_lines(orientation='horizontal',y_here=y_here,x_start=x_start,x_here=x_here,color=color,lw=lw)
            if clade.name != None and end_same and '__' not in clade.name and clade.name not in ['', ' ']:
                draw_clade_lines(orientation='horizontal',y_here=y_here,x_start=xmax,x_here=x_here,color=color,lw=lw-1, ls='-.')
            # Add node/taxon labels
            if clade.name not in (None, clade.__class__.__name__, '', ' '):
                label = label_func(clade.name)
                if end_same: xplc = xmax
                else: xplc = x_here
                if plot_labels: axes.text(xplc, y_here, " %s" % label, verticalalignment="center", horizontalalignment='left', color='k', fontsize=fs)
                leaves.append([label, xplc, y_here, 0, 'center', 'left']) 
            if clade.clades:
                # Draw a vertical line connecting all children
                y_top = y_posns[clade.clades[0]]
                y_bot = y_posns[clade.clades[-1]]
                # Only apply widths to horizontal lines, like Archaeopteryx
                draw_clade_lines(orientation='vertical',x_here=x_here,y_bot=y_bot,y_top=y_top,color=color,lw=lw)
                # Draw descendents
                for child in clade:
                    draw_clade(child, x_here, color, lw)
        elif orient_tree == 'vertical':
                draw_clade_lines(orientation='vertical', x_here=y_here, y_bot=x_start, y_top=x_here,color=color,lw=lw)
                if clade.name not in (None, clade.__class__.__name__, '', ' '):
                    draw_clade_lines(orientation='vertical',x_here=y_here, y_bot=xmax, y_top=x_here,color=color,lw=lw-1, ls='-.')
                if clade.name not in (None, clade.__class__.__name__, '', ' '):
                    label = label_func(clade.name)
                    if end_same: xplc = xmax
                    else: xplc = x_here
                    if vert_orient == 'up':
                        if plot_labels: axes.text(y_here, xplc,  " %s" % label, verticalalignment='bottom', horizontalalignment='center', color='k', rotation=90, fontsize=fs)
                        leaves.append([label, y_here, xplc, 90, 'bottom', 'center']) 
                    elif vert_orient == 'down':
                        if plot_labels: axes.text(y_here, xplc,  " %s" % label, verticalalignment='top', horizontalalignment='center', color='k', rotation=90, fontsize=fs)
                        leaves.append([label, y_here, xplc, 90, 'top', 'center']) 
                if clade.clades:
                    y_top = y_posns[clade.clades[0]]
                    y_bot = y_posns[clade.clades[-1]]
                    draw_clade_lines(orientation='horizontal', y_here=x_here, x_start=y_bot, x_here=y_top, color=color,lw=lw)
                    for child in clade:
                        draw_clade(child, x_here, color, lw, orient_tree='vertical', vert_orient=vert_orient)
    def draw_clade_polar(clade, color, lw, x_start=0.1, y_start=0, span=360):
        ymax = max(y_posns.values())
        yang = span/ymax
        xmax = max(x_posns.values())+max(x_posns.values())/30
        x_here = x_posns[clade]
        y_here = y_posns[clade]
        rad = span*np.pi/180
        rad = rad/ymax
        if y_start == 0:
            y_start = rad*y_start
        y_here = rad*y_here
        if x_here != 0: 
            axes.plot([y_start, y_here], [x_start, x_here], color=color, lw=lw)
            if clade.name != None and end_same:
                axes.plot([y_start, y_here], [x_here, xmax], color=color, lw=lw-1, linestyle='-.')
        if clade.name not in (None, clade.__class__.__name__):
            label = label_func(clade.name)
            rot = y_here*(180/np.pi)
            if end_same: xplc = xmax
            else: xplc = x_here
            if rot <= 90: va, ha = 'center', 'left'
            elif rot <= 180: va, ha, rot = 'center', 'right', rot-180
            elif rot <= 270: va, ha, rot = 'center', 'right', rot-180
            else: va, ha = 'center', 'left'
            if plot_labels: axes.text(y_here, xplc, label, color='k', rotation=rot, rotation_mode='anchor', va=va, ha=ha, fontsize=fs)
            leaves.append([label, y_here, xplc, rot, va, ha])
        if clade.clades:
            y_top = y_posns[clade.clades[0]]
            y_bot = y_posns[clade.clades[-1]]
            y_top = y_top*yang*np.pi/180
            y_bot = y_bot*yang*np.pi/180
            curve = [[y_bot, y_top], [x_here, x_here]]
            x = np.linspace(curve[0][0], curve[0][1], 500)
            y = interp1d(curve[0], curve[1])(x)
            axes.plot(x, y, color=color, lw=lw)
            ymin, ymax = min(x), max(x)
            ydiff = ymax-ymin
            count = [1 for child in clade]
            count = sum(count)-2
            locs = [ymin]
            for a in range(count):
                locs.append(ydiff/(count+1)+ymin)
            locs.append(ymax)
            count = 0
            for child in clade:
                if child.name != None: 
                    y_start = y_posns[child]*rad
                else:
                    y_start = locs[count]
                draw_clade_polar(child, color, lw, x_start=x_here, y_start=y_start, span=span)
                count += 1
    plt.sca(axes)
    if orient_tree in ['horizontal', 'vertical']:
        draw_clade(tree.root, 0, "k", plt.rcParams["lines.linewidth"], orient_tree=orient_tree, vert_orient=vert_orient)
        if orient_tree == 'horizontal':
            xmax = max(x_posns.values())
            axes.set_xlim(-0.05 * xmax, 1.25 * xmax)
            # Also invert the y-axis (origin at the top)
            # Add a small vertical margin, but avoid including 0 and N+1 on the y axis
            axes.set_ylim(max(y_posns.values()) + 0.8, 0.2)
        elif orient_tree == 'vertical':
            axes.set_xlim(max(y_posns.values()) + 0.8, 0.2)
            xmax = max(x_posns.values())
            if vert_orient == 'up':
                axes.set_ylim(-0.05 * xmax, 1.25 * xmax)
            elif vert_orient == 'down':
                axes.set_ylim(1.25 * xmax, -0.05 * xmax)
        axes.set_xticks([]), axes.set_yticks([])
    elif orient_tree == 'circular':
        print('Note that if you provided an axes for this then it must be polar orientation or it will probably look very strange')
        x_start = 0
        y_start = 0
        draw_clade_polar(tree.root, "k", plt.rcParams["lines.linewidth"], x_start=x_start, y_start=y_start, span=span)
        axes.set_ylim([0, max(x_posns.values())])
        axes.yaxis.grid(False)
        axes.set_xticks([])
        axes.set_yticklabels([])
    return leaves
finished = True
```

# R
## Import data
```{R, results='hide', fig.keep='all', eval=FALSE}
folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/'
asv_table <- read.csv(paste(folder, "exports_9.22/feature-table_w_tax.csv", sep="")) 
sampledata <- read.csv(paste(folder, "exports_9.22/metadata_complete.csv", sep="")) #read in the metadata table
phy_tree <- read_tree(paste(folder, "exports_9.22/tree.nwk", sep='')) #read in the phylogenetic tree



taxonomy = asv_table[, c(1, 150)] #take only the OTU ID and taxonomy column to a new table
asv_table = asv_table[, 1:149] #take the OTU ID and the other columns to be the ASV table
dropping = c("DNA1", "DNA2", "DNA3", "DNA4", "DNA5", "DNA6")
asv_table_new = asv_table[ , !(names(asv_table) %in% dropping)]
asv_table = asv_table_new


asv_table_num = data.matrix(asv_table[,2:147]) #convert the ASV table to a numeric matrix
asv_table_num
rownames(asv_table_num) = asv_table[,1] #give the matrix row names
asv_table = as.matrix(asv_table_num) #convert it to a matrix

taxonomy <- separate(data = taxonomy, col = taxonomy, into = c("Domain", "Phylum", "Class", "Order", "Family", "Genus", "Species"), sep = "\\;") #separate the taxonomy table so each phylogenetic level is its own column
taxmat <- taxonomy[,-1] #remove the OTU ID column from the taxonomy table
rownames(taxmat) <- taxonomy[,1] #and now give the taxonomy table the OTU IDs as row names

samples <- sampledata[, 2:10] #get the metadata columns
rownames(samples) = sampledata[,1] #and add the sample names as row names
samples = data.frame(samples, stringsAsFactors = FALSE) #convert this to a data frame

#convert these to phyloseq objects
ASV = otu_table(asv_table, taxa_are_rows = TRUE)
TAX = tax_table(taxmat)
SAMPLE = sample_data(samples)
taxa_names(TAX) <- taxonomy[,1]
physeq = phyloseq(ASV,phy_tree,TAX,SAMPLE)
taxa_names(physeq) <- paste('ASV', 1:ntaxa(physeq), sep="")
```

```{R, results='hide', fig.keep='all', fig.height=5}
tax = tax_table(physeq)
write.csv(tax, paste(folder, "R_objects_new/tax_table_new.csv", sep=""))
#then ran the add_tax.py script 
```

```{R, results='hide', fig.keep='all', fig.height=5}
taxonomy <- read.csv(paste(folder, "R_objects_new/tax_table_filled_new.csv", sep="")) 
rownames(taxonomy) <- taxonomy[,1] 
taxonomy = taxonomy[, 2:8]
TAX = tax_table(taxonomy)
taxa_names(TAX) <- rownames(taxonomy)
tax_table(physeq) = TAX
```

## Normalise

We'll perform all of the normalisations (as we did above) that we will want to use at some point
```{R, results='hide', fig.keep='all', eval=FALSE}
physeq_rare <- rarefy_even_depth(physeq, sample.size = min(sample_sums(physeq)), replace = TRUE, trimOTUs = TRUE, verbose = TRUE) #rarefy to the lowest sample depth
physeq_clr <- microbiome::transform(physeq, "clr") #convert to CLR
physeq_relabun  <- transform_sample_counts(physeq, function(x) (x / sum(x))*100) #convert to relative abundance
saveRDS(physeq, file= paste(folder, "R_objects_new/physeq_new.rds", sep=""))
saveRDS(physeq_rare, file= paste(folder, "R_objects_new/physeq_rare_new.rds", sep=""))
saveRDS(physeq_clr, file= paste(folder, "R_objects_new/physeq_clr_new.rds", sep=""))
saveRDS(physeq_relabun, file= paste(folder, "R_objects_new/physeq_relabun_new.rds", sep=""))
```

```{R, results='hide', fig.keep='all', eval=FALSE}
asv_table=otu_table(physeq)
asv_table=as.data.frame(asv_table)
write.csv(asv_table, paste(folder, "R_objects_new/asv_table_new.csv", sep=""))
```
##have run the rclr.py script
```{R, results='hide', fig.keep='all'}
asv_table_rclr = read.csv(paste(folder, "R_objects_new/asv_table_rclr_new.csv", sep="")) 
physeq_rclr=physeq
asv_table_rclr
asv_table_num = data.matrix(asv_table_rclr[,2:146]) #convert the ASV table to a numeric matrix (changed 147 to 146 6/29/22 don't know why columnds decrease, one sample lost?)
rownames(asv_table_num) = asv_table_rclr[,1] #give the matrix row names
asv_table_rclr = as.matrix(asv_table_num)
ASV = otu_table(asv_table_rclr, taxa_are_rows = TRUE)
otu_table(physeq_rclr)=ASV
saveRDS(physeq_rclr, file= paste(folder, "R_objects_new/physeq_rclr_new.rds", sep=""))
```

##R objects
```{R, results='hide', fig.keep='all'}
#16S
physeq_rare_16S = readRDS(paste(folder, "R_objects_new/", "physeq_rare_new.rds", sep=""))
physeq_relabun_16S = readRDS(paste(folder, "R_objects_new/", "physeq_relabun_new.rds", sep=""))
physeq_rclr_16S = readRDS(paste(folder, "R_objects_new/", "physeq_rclr_new.rds", sep=""))
physeq_clr_16S = readRDS(paste(folder, "R_objects_new/", "physeq_clr_new.rds", sep=""))
physeq_16S = readRDS(paste(folder, "R_objects_new/", "physeq.rds", sep=""))

#ITS
physeq_rare_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq_rare.rds", sep=""))
physeq_relabun_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq_relabun.rds", sep=""))
physeq_rclr_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq_rclr.rds", sep=""))
physeq_clr_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq_clr.rds", sep=""))
physeq_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq.rds", sep=""))

#16S
tax = as.data.frame(tax_table(physeq_16S))
write.csv(tax, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "taxonomy_16S.csv", sep=""))

tree = phy_tree(physeq_16S)
write.tree(tree, file=paste(folder, "robyn_analysis/tables_convert_from_maggie/", "tree_16S.tree", sep=""))

physeq_rare_16S_df = as.data.frame(otu_table(physeq_rare_16S))
write.csv(physeq_rare_16S_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_rare_16S.csv", sep=""))
physeq_relabun_16S_df = as.data.frame(otu_table(physeq_relabun_16S))
write.csv(physeq_relabun_16S_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_relabun_16S.csv", sep=""))
physeq_rclr_16S_df = as.data.frame(otu_table(physeq_rclr_16S))
write.csv(physeq_rclr_16S_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_rclr_16S.csv", sep=""))
physeq_clr_16S_df = as.data.frame(otu_table(physeq_clr_16S))
write.csv(physeq_clr_16S_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_clr_16S.csv", sep=""))
physeq_16S_df = as.data.frame(otu_table(physeq_16S))
write.csv(physeq_16S_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_16S.csv", sep=""))
md = as.data.frame(sample_data(physeq_16S))
write.csv(md, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "metadata.csv", sep=""))

#ITS
tax = as.data.frame(tax_table(physeq_ITS))
write.csv(tax, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "taxonomy_ITS.csv", sep=""))

physeq_rare_ITS_df = as.data.frame(otu_table(physeq_rare_ITS))
write.csv(physeq_rare_ITS_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_rare_ITS.csv", sep=""))
physeq_relabun_ITS_df = as.data.frame(otu_table(physeq_relabun_ITS))
write.csv(physeq_relabun_ITS_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_relabun_ITS.csv", sep=""))
physeq_rclr_ITS_df = as.data.frame(otu_table(physeq_rclr_ITS))
write.csv(physeq_rclr_ITS_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_rclr_ITS.csv", sep=""))
physeq_clr_ITS_df = as.data.frame(otu_table(physeq_clr_ITS))
write.csv(physeq_clr_ITS_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_clr_ITS.csv", sep=""))
physeq_ITS_df = as.data.frame(otu_table(physeq_ITS))
write.csv(physeq_ITS_df, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "ft_ITS.csv", sep=""))
md = as.data.frame(sample_data(physeq_ITS))
write.csv(md, paste(folder, "robyn_analysis/tables_convert_from_maggie/", "metadata_ITS.csv", sep=""))
```

##What we'll use:
```{R}
folder = '/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/'
physeq_relabun_16S = readRDS(paste(folder, "R_objects_new/", "physeq_relabun_new.rds", sep=""))
physeq_rclr_16S = readRDS(paste(folder, "R_objects_new/", "physeq_rclr_new.rds", sep=""))
physeq_16S = readRDS(paste(folder, "R_objects_new/", "physeq.rds", sep=""))

physeq_relabun_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq_relabun.rds", sep=""))
physeq_rclr_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq_rclr.rds", sep=""))
physeq_ITS = readRDS(paste(folder, "R_objects_ITS/", "physeq.rds", sep=""))
```

# PERMANOVA 16S

Bray-Curtis relative abundance, weighted unifrac relative abundance, unweighted unifrac relative abundance, robust Aitchison's distance, PHILR distance. 

Bray-Curtis on relative abundance:
```{R}
ps = physeq_relabun_16S
distance <- phyloseq::distance(ps, method="bray", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/16S_relabun_braycurtis.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_16S_relabun_braycurtis.csv', sep=''))

#p-adjust using the previous adonis table 
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_16S_relabun_braycurtis.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
#write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_braycurtis_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_braycurtis_padj.csv', sep=''))
```

Weighted UniFrac on relative abundance:
```{R}
ps = physeq_relabun_16S
distance <- phyloseq::distance(ps, method="unifrac", weighted=T)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/16S_relabun_weightedunifrac.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_16S_relabun_weightedunifrac.csv', sep=''))

#p-adjust using the previous adonis table
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_16S_relabun_weightedunifrac.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_weightedunifrac_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_weightedunifrac_padj.csv', sep=''))
```

Unweighted UniFrac on relative abundance:
```{R}
ps = physeq_relabun_16S
distance <- phyloseq::distance(ps, method="unifrac", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/16S_relabun_unweightedunifrac.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_16S_relabun_unweightedunifrac.csv', sep=''))

#p-adjust using the previous adonis table
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_16S_relabun_unweightedunifrac.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_unweightedunifrac_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_unweightedunifrac_padj.csv', sep=''))
```

Robust Aitchison's distance:
```{R}
ps = physeq_rclr_16S
distance <- phyloseq::distance(ps, method="euclidean", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/16S_rclr_euclidean.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_16S_rclr_euclidean.csv', sep=''))

#p-adjust using the previous adonis table
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_16S_rclr_euclidean.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_rclr_euclidean_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_rclr_euclidean_padj.csv', sep=''))
```

PHILR distance:
```{R}
physeq_philr = physeq_16S
physeq_philr <- transform_sample_counts(physeq_philr, function(x) x+1)
phy_tree(physeq_philr) <- makeNodeLabel(phy_tree(physeq_philr), method="number", prefix='n')
otu.table <- t(otu_table(physeq_philr))
tree <- phy_tree(physeq_philr)
ps = physeq_philr

physeq.philr <- philr(otu.table, tree, part.weights='enorm.x.gm.counts', ilr.weights='blw.sqrt')
philr.dist <- dist(physeq.philr, method="euclidean")
dist_mat = as.matrix(philr.dist)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/16S_philr.csv', sep=''))
ads = adonis(dist ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_16S_philr.csv', sep=''))

#p-adjust using the previous adonis table
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_16S_philr.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_philr_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_16S_relabun_philr_padj.csv', sep=''))
```

# PERMANOVA ITS

Bray-Curtis relative abundance, robust Aitchison's distance. 

Bray-Curtis on relative abundance:
```{R}
ps = physeq_relabun_ITS
distance <- phyloseq::distance(ps, method="bray", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/ITS_relabun_braycurtis.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_ITS_relabun_braycurtis.csv', sep=''))

#p-adjust using the previous adonis table
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_ITS_relabun_braycurtis.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_relabun_braycurtis_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
ads_table
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_relabun_braycurtis_padj.csv', sep=''))
```

Robust Aitchison's distance:
```{R}
ps = physeq_rclr_ITS
distance <- phyloseq::distance(ps, method="euclidean", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/ITS_rclr_euclidean.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_ITS_rclr_euclidean.csv', sep=''))

#p-adjust using the previous adonis table 
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_ITS_rclr_euclidean.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_rclr_euclidean_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_rclr_euclidean_padj.csv', sep=''))
```

# PERMANOVA ITS genus

Bray-Curtis relative abundance, robust Aitchison's distance. 

Bray-Curtis on relative abundance:
```{R}
ps = physeq_relabun_ITS
rnk = "ta6"
ps = tax_glom(ps, taxrank=rnk, NArm=TRUE)
distance <- phyloseq::distance(ps, method="bray", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/ITS_genus_relabun_braycurtis.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_ITS_genus_relabun_braycurtis.csv', sep=''))

#p-adjust using the previous adonis table 
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_ITS_genus_relabun_braycurtis.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_genus_relabun_braycurtis_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_genus_relabun_braycurtis_padj.csv', sep=''))
```

Robust Aitchison's distance:
```{R}
ps = physeq_rclr_ITS
rnk = "ta6"
ps = tax_glom(ps, taxrank=rnk, NArm=TRUE)
distance <- phyloseq::distance(ps, method="euclidean", weighted=F)
dist_mat = as.matrix(distance)
write.csv(dist_mat, paste(folder, 'robyn_analysis/distances/ITS_genus_rclr_euclidean.csv', sep=''))
ads = adonis(distance ~ sample_data(ps)$Treatment*sample_data(ps)$Location*sample_data(ps)$Soil_Horizon*sample_data(ps)$Sample_within_site*sample_data(ps)$Season, parallel=12)
ads_tab = as.data.frame(ads$aov.tab)
write.csv(ads_tab, paste(folder, 'robyn_analysis/stats_tests/adonis_ITS_genus_rclr_euclidean.csv', sep=''))

#p-adjust using the previous adonis table 
folder = "/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/"
ads <- read.csv(paste(folder, "robyn_analysis/stats_tests/adonis_ITS_genus_rclr_euclidean.csv", sep = ""))
ads_table = as.data.frame(ads)
p_values = data.frame(ads_table$Pr..F.)
p_values_mat = as.matrix(p_values)
padj = p.adjust(p_values_mat, method = "fdr")
padj_tab = as.data.frame(padj)
write.csv(padj_tab, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_genus_rclr_euclidean_padj_only.csv', sep=''))
ads_table$p_adjust <- c(padj)
write.csv(ads_table, paste(folder, 'robyn_analysis/stats_tests_mag/p_adjust/adonis_ITS_genus_rclr_euclidean_padj.csv', sep=''))
```

# Stacked bar plots

Function:
```{python}
def barplot(ft, tax, md):
  rename = {}
  for row in tax.index:
    rename[row] = tax.loc[row, 'ta3']+' '+tax.loc[row, 'ta6']
  samples = {}
  samples_treat_loc_only = {}
  for col in ft.columns:
    samples[col] = md.loc[col, 'Treatment_Location_Horizon']
    new_sample = md.loc[col, 'Soil_Horizon'].strip()+' '+md.loc[col, 'Treatment'].strip()
    samples_treat_loc_only[md.loc[col, 'Treatment_Location_Horizon']] = new_sample
  level = ft.copy(deep=True).rename(index=rename, columns=samples)
  level = level.groupby(by=level.index, axis=0).sum()
  level = level.groupby(by=level.columns, axis=1).mean().rename(columns=samples_treat_loc_only)
  level_group = level.groupby(by=level.columns, axis=1).mean()
  level_group['Mean'] = level_group.mean(axis=1)
  level_group = level_group.sort_values(by=['Mean'], ascending=False)
  level_group = level_group.head(30)
  level = level.loc[level_group.index, :]
  order = list(set(sorted(list(level.columns))))
  order = ['Upper Forest Floor Control Site1', 'Upper Forest Floor Control Site2', 'Upper Forest Floor Control Site3', 'Upper Forest Floor Control Site4', 'Upper Forest Floor Control Site5', 'Upper Forest Floor Treatment Site1', 'Upper Forest Floor Treatment Site2', 'Upper Forest Floor Treatment Site3', 'Upper Forest Floor Treatment Site4', 'Upper Forest Floor Treatment Site5', 'Lower Forest Floor Control Site1', 'Lower Forest Floor Control Site2', 'Lower Forest Floor Control Site3', 'Lower Forest Floor Control Site4', 'Lower Forest Floor Control Site5', 'Lower Forest Floor Treatment Site1', 'Lower Forest Floor Treatment Site2', 'Lower Forest Floor Treatment Site3', 'Lower Forest Floor Treatment Site4', 'Lower Forest Floor Treatment Site5', 'Upper B Horizon Control Site1', 'Upper B Horizon Control Site2', 'Upper B Horizon Control Site3', 'Upper B Horizon Control Site4', 'Upper B Horizon Control Site5','Upper B Horizon Treatment Site1', 'Upper B Horizon Treatment Site2', 'Upper B Horizon Treatment Site3', 'Upper B Horizon Treatment Site4', 'Upper B Horizon Treatment Site5']
  level = level.loc[:, order]
  ax = level.transpose().plot.bar(stacked=True, width=0.8, edgecolor='k')
  lg = ax.legend(loc='upper left', bbox_to_anchor=(1.02, 1.02), ncol=1, fontsize=8)  
  yl = ax.set_ylabel('Relative abundance (%)')
  return
```

16S:
```{python}
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_16S.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_16S.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_16S.csv', index_col=0, header=0)

barplot(ft, tax, md)
plt.savefig(folder+'robyn_analysis/figures/stacked_bar_16S.png', dpi=600, bbox_inches='tight')
```

ITS:
```{python}
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_ITS.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_ITS.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_ITS.csv', index_col=0, header=0)

barplot(ft, tax, md)
plt.savefig(folder+'robyn_analysis/figures/stacked_bar_ITS.png', dpi=600, bbox_inches='tight')
```

# Heatmaps relative abundance

Function:
```{python}
def make_heatmap(ft, tax, md):
  rename = {}
  for row in tax.index:
    rename[row] = tax.loc[row, 'ta3']+' '+tax.loc[row, 'ta6']
  samples = {}
  samples_treat_loc_only = {}
  for col in ft.columns:
    samples[col] = md.loc[col, 'Treatment_Location_Horizon']
    new_sample = md.loc[col, 'Soil_Horizon'].strip()+' '+md.loc[col, 'Treatment'].strip()
    samples_treat_loc_only[md.loc[col, 'Treatment_Location_Horizon']] = new_sample
  level = ft.copy(deep=True).rename(index=rename, columns=samples)
  level = level.groupby(by=level.index, axis=0).sum()
  level = level.groupby(by=level.columns, axis=1).mean().rename(columns=samples_treat_loc_only)
  level_group = level.groupby(by=level.columns, axis=1).mean()
  level_group['Mean'] = level_group.mean(axis=1)
  level_group = level_group.sort_values(by=['Mean'], ascending=False)
  level_group = level_group.head(30)
  level_group = level_group.sort_values(by=['Mean'], ascending=True)
  level = level.loc[level_group.index, :]
  order = list(set(sorted(list(level.columns))))
  order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
  level = level.loc[:, order]
  ma, mi = max(level.max(axis=1)), min(level.min(axis=1))
  fig = plt.figure(figsize=(13,10))
  ax = plt.subplot(111)
  pc = plt.pcolor(level, axes=ax, edgecolor='k', vmax=10)
  xl = plt.xticks([a+0.5 for a in range(len(level.columns))], level.columns, rotation=90)
  yl = plt.yticks([a+0.5 for a in range(len(level.index))], level.index)
  mid = np.mean([ma, mi])
  for x in range(len(level.columns)):
    for y in range(len(level.index)):
      num = level.iloc[y, x]
      if num > 5: color = 'k'
      else: color = 'w'
      ax.text(x+0.5, y+0.5, str(round(num, 2)), color=color, fontsize=8, ha='center', va='center')
  return
```

16S:
```{python}
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_16S.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_16S.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_16S.csv', index_col=0, header=0)

make_heatmap(ft, tax, md)
plt.savefig(folder+'robyn_analysis/figures/heatmap_16S.png', dpi=600, bbox_inches='tight')
```

ITS:
```{python}
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_ITS.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_ITS.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_ITS.csv', index_col=0, header=0)

make_heatmap(ft, tax, md)
plt.savefig(folder+'robyn_analysis/figures/heatmap_ITS.png', dpi=600, bbox_inches='tight')
```

# Tree and heatmap

16S get trees:
```{python}
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_16S.csv', index_col=0, header=0)
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_16S.csv', index_col=0, header=0)
# tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_ITS.csv', index_col=0, header=0)
# ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_ITS.csv', index_col=0, header=0)
```

Get trees for all levels:
```{R}
tax_table = py$tax
TAX = tax_table(tax_table)
rownames(TAX) = rownames(tax_table)
phy_tree <- read_tree(paste(py$folder, 'robyn_analysis/tables_convert_from_maggie/tree_ITS.tree', sep=''))
ft = py$ft
table_num = data.matrix(ft[,1:146])
rownames(table_num) = rownames(ft)
table = otu_table(table_num, taxa_are_rows = TRUE)
physeq_all = phyloseq(table, phy_tree, TAX)

ranks = c("ta6", "ta5", "ta4", "ta3", "ta2")
names = c("genus", "family", "order", "class", "phylum")
for (a in 1:length(ranks)) {
  physeq_level = tax_glom(physeq_all, taxrank=ranks[a])
  level_tree = phy_tree(physeq_level)
  write.tree(level_tree, paste(py$folder, 'robyn_analysis/processing/', names[a], '_tree.nwk', sep=''))
}
```

## 16S

```{python, eval=FALSE}
plt.figure(figsize=(50,30))
tree_names = ['phylum', 'class', 'order', 'family', 'genus']
letters = ['A', 'B', 'C', 'D', 'E']
tax_dict = {}
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_16S.csv', index_col=0, header=0)
for row in tax.index:
  tax_dict[row] = tax.loc[row, :].values
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_16S.csv', index_col=0, header=0)
ft_clr = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rclr_16S.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_16S.csv', index_col=0, header=0)

col_count, row_count = 0, 0
width = [2, 2, 2, 2, 2]
rc, cc = 60, 32 # number of rows, number of columns
rs = 25
for a in range(5):
  if a == 3: col_count, row_count = 0, 32
  ax_tree = plt.subplot2grid((rc,cc),(row_count,col_count), colspan=2, rowspan=rs, frameon=False)
  plt.title('   '+letters[a]+'   '+tree_names[a].capitalize()+'\n\n', loc='left', fontweight='bold', fontsize=16)
  col_count += 2
  ax_labels = plt.subplot2grid((rc,cc),(row_count,col_count), colspan=width[a], rowspan=rs, frameon=False)
  col_count += width[a]
  plt.xticks([]), plt.yticks([])
  ax_heat_prev = plt.subplot2grid((rc,cc),(row_count,col_count), colspan=2, rowspan=rs)
  tti = plt.xticks([]), plt.yticks([]), plt.title('Prevalence', fontweight='bold')
  ax_heat_abun = plt.subplot2grid((rc,cc),(row_count,col_count+2), colspan=2, rowspan=rs)
  tti = plt.xticks([]), plt.yticks([]), plt.title('Relative\nabundance (%)', fontweight='bold')
  ax_heat_clr = plt.subplot2grid((rc,cc),(row_count,col_count+4), colspan=2, rowspan=rs)
  tti, plt.xticks([]), plt.yticks([]), plt.title('CLR\nabundance', fontweight='bold')
  col_count += 7
  ft_level = ft.copy(deep=True)
  ft_clr_level = ft_clr.copy(deep=True)
  rename_level, rename_level_opposite = {}, {}
  tree_name = folder+'robyn_analysis/processing/'+tree_names[a]+'_tree.nwk'
  for row in ft_level.index:
    rename_level[row] = tax_dict[row][a+1]
    rename_level_opposite[tax_dict[row][a+1]] = row
  ft_level = ft_level.rename(index=rename_level)
  ft_level = ft_level.groupby(by=ft_level.index, axis=0).sum()
  ft_clr_level = ft_clr_level.rename(index=rename_level)
  ft_clr_level = ft_clr_level.groupby(by=ft_clr_level.index, axis=0).sum()
  if ft_level.shape[0] > 30:
    ft_group = ft_level.copy(deep=True).transpose()
    rename_samples = {}
    for sample in ft_group.index:
      rename_samples[sample] = md.loc[sample, 'Treatment_Horizon']
    ft_group = ft_group.rename(index=rename_samples)
    ft_group = ft_group.groupby(by=ft_group.index, axis=0).mean().transpose()
    ft_group['Mean'] = ft_group.mean(axis=1)
    ft_group = ft_group.sort_values(by=['Mean'], ascending=False)
    ft_group = ft_group.iloc[:30, :]
    ft_level = ft_level.loc[ft_group.index, :]
    ft_clr_level = ft_clr_level.loc[ft_group.index, :]
    tree = Tree(tree_name, format=1)
    rename_tree_level = {}
    keeping = []
    for node in tree.traverse("postorder"):
      if node.name in rename_level:
        rename_tree_level[rename_level[node.name]] = node.name
        if rename_level[node.name] in ft_level.index:
          keeping.append(node.name)
    tree.prune(keeping)
    tree_name = folder+'robyn_analysis/processing/'+tree_names[a]+'_reduced_tree.txt'
    tree.write(outfile=tree_name, format=1)
  tree = Phylo.read(tree_name, "newick")
  leaves = draw_tree(tree, axes=ax_tree, end_same=True, plot_labels=False)
  order = []
  for leaf in leaves[1:]:
    if leaf[0] in rename_level:
      tx = ax_tree.text(leaf[1], leaf[2], '  '+rename_level[leaf[0]], va=leaf[4], ha=leaf[5])
      order.append(rename_level[leaf[0]])
  ft_level = ft_level.loc[order, :]
  ft_clr_level = ft_clr_level.loc[order, :]
  plt.ylim([0.5, leaves[-1][2]+0.5])
  rename_sample = {}
  for col in ft_level.columns:
    rn = md.loc[col, 'Soil_Horizon']+' '+md.loc[col, 'Treatment']
    rename_sample[col] = rn.replace('  ', ' ').strip()
  ft_level = ft_level.rename(columns=rename_sample)
  ft_clr_level = ft_clr_level.rename(columns=rename_sample)
  ft_level_prev = ft_level.copy(deep=True).transpose()
  ft_level_abun = ft_level.copy(deep=True).transpose()
  ft_clr_level_abun = ft_clr_level.copy(deep=True).transpose()
  ft_level_prev[ft_level_prev > 0] = 1
  treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
  ft_level_prev = ft_level_prev.groupby(by=ft_level_prev.index, axis=0).mean().transpose().loc[:, treat_order]
  ft_level_abun = ft_level_abun.groupby(by=ft_level_abun.index, axis=0).mean().transpose().loc[:, treat_order]
  ft_clr_level_abun = ft_clr_level_abun.groupby(by=ft_clr_level_abun.index, axis=0).mean().transpose().loc[:, treat_order]
  min_prev, max_prev, min_abun, max_abun, min_clr, max_clr = min(ft_level_prev.min(axis=1)), max(ft_level_prev.max(axis=1)), min(ft_level_abun.min(axis=1)), max(ft_level_abun.max(axis=1)), min(ft_clr_level_abun.min(axis=1)), max(ft_clr_level_abun.max(axis=1))
  mid_prev, mid_abun, mid_clr = np.mean([min_prev, max_prev]), np.mean([min_abun, max_abun]), np.mean([min_clr, max_clr])
  print(min_prev, max_prev, min_abun, max_abun, min_clr, max_clr)
  plt.sca(ax_heat_prev)
  plt.pcolor(ft_level_prev, cmap='PuBu', edgecolor='k')
  plt.sca(ax_heat_abun)
  plt.pcolor(ft_level_abun, cmap='RdPu', edgecolor='k', vmax=10)
  plt.sca(ax_heat_clr)
  plt.pcolor(ft_clr_level_abun, cmap='bwr', edgecolor='k', vmin=-10, vmax=10)
  axes, dfs, mids = [ax_heat_prev, ax_heat_abun, ax_heat_clr], [ft_level_prev, ft_level_abun, ft_clr_level_abun], [0.5, 5, 5]
  x = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]
  for z in range(len(axes)):
    for y in range(len(dfs[z].index.values)):
      tax = dfs[z].index.values[y]
      for t in range(len(treat_order)):
        col = 'k'
        val = dfs[z].loc[tax, treat_order[t]]
        rnd = 2
        if abs(val) >= mids[z]: col = 'w'
        if abs(val) >= 1: rnd = 1
        if abs(val) >= 10:
          tx = axes[z].text(x[t], y+0.5, str(int(val)), ha='center', va='center', color=col)
        else:
          tx = axes[z].text(x[t], y+0.5, str(round(val,rnd)), ha='center', va='center', color=col)
  for ax in [ax_heat_prev, ax_heat_abun, ax_heat_clr]:
    plt.sca(ax)
    xt = plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5, 5.5], [t.replace('Treat', '\nTreat').replace('Cont', '\nCont') for t in treat_order], rotation=90)

plt.savefig(folder+'robyn_analysis/figures/heatmap_all_levels_16S.png', dpi=600, bbox_inches='tight')
```

## ITS

```{python, eval=FALSE}
plt.figure(figsize=(50,30))
tree_names = ['phylum', 'class', 'order', 'family', 'genus']
letters = ['A', 'B', 'C', 'D', 'E']
tax_dict = {}
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_ITS.csv', index_col=0, header=0)
for row in tax.index:
  tax_dict[row] = tax.loc[row, :].values
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_ITS.csv', index_col=0, header=0)
ft_clr = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rclr_ITS.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_ITS.csv', index_col=0, header=0)

col_count, row_count = 0, 0
width = [2, 2, 2, 2, 2]
rc, cc = 60, 32 # number of rows, number of columns
rs = 25
for a in range(5):
  if a == 3: col_count, row_count = 0, 32
  ax_labels = plt.subplot2grid((rc,cc),(row_count,col_count), colspan=width[a], rowspan=rs, frameon=False)
  plt.title('   '+letters[a]+'   '+tree_names[a].capitalize()+'\n\n', loc='left', fontweight='bold', fontsize=16)
  col_count += width[a]
  plt.xticks([]), plt.yticks([])
  ax_heat_prev = plt.subplot2grid((rc,cc),(row_count,col_count), colspan=2, rowspan=rs)
  tti = plt.xticks([]), plt.yticks([]), plt.title('Prevalence', fontweight='bold')
  ax_heat_abun = plt.subplot2grid((rc,cc),(row_count,col_count+2), colspan=2, rowspan=rs)
  tti = plt.xticks([]), plt.yticks([]), plt.title('Relative\nabundance (%)', fontweight='bold')
  ax_heat_clr = plt.subplot2grid((rc,cc),(row_count,col_count+4), colspan=2, rowspan=rs)
  tti, plt.xticks([]), plt.yticks([]), plt.title('CLR\nabundance', fontweight='bold')
  col_count += 7
  ft_level = ft.copy(deep=True)
  ft_clr_level = ft_clr.copy(deep=True)
  rename_level, rename_level_opposite = {}, {}
  tree_name = folder+'robyn_analysis/processing/'+tree_names[a]+'_tree.nwk'
  for row in ft_level.index:
    rename_level[row] = tax_dict[row][a+1]
    rename_level_opposite[tax_dict[row][a+1]] = row
  ft_level = ft_level.rename(index=rename_level)
  ft_level = ft_level.groupby(by=ft_level.index, axis=0).sum()
  ft_clr_level = ft_clr_level.rename(index=rename_level)
  ft_clr_level = ft_clr_level.groupby(by=ft_clr_level.index, axis=0).sum()
  if ft_level.shape[0] > 30:
    ft_group = ft_level.copy(deep=True).transpose()
    rename_samples = {}
    for sample in ft_group.index:
      rename_samples[sample] = md.loc[sample, 'Treatment_Horizon']
    ft_group = ft_group.rename(index=rename_samples)
    ft_group = ft_group.groupby(by=ft_group.index, axis=0).mean().transpose()
    ft_group['Mean'] = ft_group.mean(axis=1)
    ft_group = ft_group.sort_values(by=['Mean'], ascending=False)
    ft_group = ft_group.iloc[:30, :]
    ft_level = ft_level.loc[ft_group.index, :]
    ft_clr_level = ft_clr_level.loc[ft_group.index, :]
  order = list(ft_level.index.values)
  ft_level = ft_level.loc[order, :]
  ft_clr_level = ft_clr_level.loc[order, :]
  #plt.ylim([0.5, len(order)+0.5])
  rename_sample = {}
  for col in ft_level.columns:
    rn = md.loc[col, 'Soil_Horizon']+' '+md.loc[col, 'Treatment']
    rename_sample[col] = rn.replace('  ', ' ').strip()
  ft_level = ft_level.rename(columns=rename_sample)
  ft_clr_level = ft_clr_level.rename(columns=rename_sample)
  ft_level_prev = ft_level.copy(deep=True).transpose()
  ft_level_abun = ft_level.copy(deep=True).transpose()
  ft_clr_level_abun = ft_clr_level.copy(deep=True).transpose()
  ft_level_prev[ft_level_prev > 0] = 1
  treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
  ft_level_prev = ft_level_prev.groupby(by=ft_level_prev.index, axis=0).mean().transpose().loc[:, treat_order]
  ft_level_abun = ft_level_abun.groupby(by=ft_level_abun.index, axis=0).mean().transpose().loc[:, treat_order]
  ft_clr_level_abun = ft_clr_level_abun.groupby(by=ft_clr_level_abun.index, axis=0).mean().transpose().loc[:, treat_order]
  min_prev, max_prev, min_abun, max_abun, min_clr, max_clr = min(ft_level_prev.min(axis=1)), max(ft_level_prev.max(axis=1)), min(ft_level_abun.min(axis=1)), max(ft_level_abun.max(axis=1)), min(ft_clr_level_abun.min(axis=1)), max(ft_clr_level_abun.max(axis=1))
  mid_prev, mid_abun, mid_clr = np.mean([min_prev, max_prev]), np.mean([min_abun, max_abun]), np.mean([min_clr, max_clr])
  plt.sca(ax_heat_prev)
  plt.pcolor(ft_level_prev, cmap='PuBu', edgecolor='k')
  yt = plt.yticks([a+0.5 for a in range(len(order))], order)
  plt.sca(ax_heat_abun)
  plt.pcolor(ft_level_abun, cmap='RdPu', edgecolor='k', vmax=10)
  plt.sca(ax_heat_clr)
  plt.pcolor(ft_clr_level_abun, cmap='bwr', edgecolor='k', vmin=-10, vmax=10)
  axes, dfs, mids = [ax_heat_prev, ax_heat_abun, ax_heat_clr], [ft_level_prev, ft_level_abun, ft_clr_level_abun], [0.5, 5, 5]
  x = [0.5, 1.5, 2.5, 3.5, 4.5, 5.5]
  for z in range(len(axes)):
    for y in range(len(dfs[z].index.values)):
      tax = dfs[z].index.values[y]
      for t in range(len(treat_order)):
        col = 'k'
        val = dfs[z].loc[tax, treat_order[t]]
        rnd = 2
        rnd = 2
        if abs(val) >= mids[z]: col = 'w'
        if abs(val) >= 1: rnd = 1
        if abs(val) >= 10:
          tx = axes[z].text(x[t], y+0.5, str(int(val)), ha='center', va='center', color=col)
        else:
          tx = axes[z].text(x[t], y+0.5, str(round(val,rnd)), ha='center', va='center', color=col)
  for ax in [ax_heat_prev, ax_heat_abun, ax_heat_clr]:
    plt.sca(ax)
    xt = plt.xticks([0.5, 1.5, 2.5, 3.5, 4.5, 5.5], [t.replace('Treat', '\nTreat').replace('Cont', '\nCont') for t in treat_order], rotation=90)

plt.savefig(folder+'robyn_analysis/figures/heatmap_all_levels_ITS.png', dpi=600, bbox_inches='tight')
```


# Alpha diversity R

Treatment 16S:
```{R}
plot_richness(physeq_rare_16S, x="Treatment", measures=c("Observed", "Chao1", "Simpson", "Shannon")) + geom_boxplot()
```

Horizon 16S:
```{R}
plot_richness(physeq_rare_16S, x="Soil_Horizon", measures=c("Observed", "Chao1", "Simpson", "Shannon")) + geom_boxplot()
```

Treatment ITS:
```{R}
plot_richness(physeq_rare_ITS, x="Treatment", measures=c("Observed", "Chao1", "Simpson", "Shannon")) + geom_boxplot()
```

Horizon ITS:
```{R}
plot_richness(physeq_rare_ITS, x="Soil_Horizon", measures=c("Observed", "Chao1", "Simpson", "Shannon")) + geom_boxplot()
```

# Alpha diversity python

16S:
```{python}
#Treatment, Horizon, Treatment and horizon #2, 3, 6
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rare_16S.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata.csv', index_col=0, header=0)
tree = read(folder+'robyn_analysis/tables_convert_from_maggie/tree_16S.tree', format="newick", into=TreeNode)
groups = [['Control', 'Treatment'], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon'], ['Control_Upper Forest Floor', 'Treatment_Upper Forest Floor', 'Control_Lower Forest Floor', 'Treatment_Lower Forest Floor', 'Control_Upper B Horizon', 'Treatment_Upper B Horizon']]
color_dict = {'Control':'#16A085', 'Treatment':'#F1C40F', 'Upper Forest Floor':'#E74C3C', 'Lower Forest Floor':'#8E44AD', 'Upper B Horizon':'#3498DB'}
colors = [[color_dict['Control'], color_dict['Treatment']], [color_dict['Upper Forest Floor'], color_dict['Lower Forest Floor'], color_dict['Upper B Horizon']], [color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment']]]
x_labs = [['Control', 'Treatment'], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon'], ['Control', 'Treatment', 'Control', 'Treatment', 'Control', 'Treatment']]
x = [[0,1], [0,1,2], [0,1,2.5,3.5,5,6]]
compare = [[[0,1]], [[0,1], [0,2], [1,2]], [[0,1], [2,3], [4,5]]]
x_locs_hor, x_labs_hor = [0.5, 3, 5.5], groups[1]

a_div_measures = ['observed_otus', 'chao1', 'shannon', 'simpson', 'faith_pd']
a_div_labels = ['Number of ASVs', 'Chao1 richness', 'Shannon diversity', "Simpson's diversity", "Faith's phylogenetic diversity"]
fig = plt.figure(figsize=(10,12.5))
for a in range(len(a_div_measures)):
  axes = [plt.subplot2grid((len(a_div_measures),11), (a,0), colspan=2), plt.subplot2grid((len(a_div_measures),11), (a,2), colspan=3), plt.subplot2grid((len(a_div_measures),11), (a,5), colspan=6)]
  if a_div_measures[a] != 'faith_pd': alpha_div = alpha_diversity(a_div_measures[a], ft.transpose())
  else: alpha_div = alpha_diversity(a_div_measures[a], ft.transpose(), otu_ids=ft.index.values, tree=tree, validate=False)
  alpha_div = alpha_div.to_frame().rename(columns={0:a_div_measures[a]})
  alpha_div.index = ft.columns
  for b in range(len(groups)):
    plt.sca(axes[b])
    this_group = {}
    for c in range(len(groups[b])): this_group[groups[b][c]] = []
    for sample in alpha_div.index:
      if b == 0: md_group = md.loc[sample, 'Treatment'].strip()
      elif b == 1: md_group = md.loc[sample, 'Soil_Horizon'].strip()
      else: md_group = md.loc[sample, 'Treatment'].strip()+'_'+md.loc[sample, 'Soil_Horizon'].strip()
      this_group[md_group].append(alpha_div.loc[sample, a_div_measures[a]])
    for d in range(len(groups[b])):
      box = axes[b].boxplot(this_group[groups[b][d]], positions=[x[b][d]], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      scat = axes[b].scatter(np.random.normal(x[b][d], scale=0.075, size=len(this_group[groups[b][d]])), this_group[groups[b][d]], color=colors[b][d], alpha=0.5, edgecolors='gray')
    if a < len(a_div_measures)-1: ti = plt.xticks(x[b], [])
    else: 
      ti = plt.xticks(x[b], x_labs[b], rotation=90)
      if b == 2:
        for e in range(len(x_locs_hor)):
          xl = plt.text(x_locs_hor[e], -75, x_labs_hor[e], ha='center', va='top')
    high, low = float(axes[b].get_ylim()[1]), float(axes[b].get_ylim()[0])
    span = high-low
    diff = span*0.01
    high = high+diff*8
    sig = 0
    for o in range(len(compare[b])):
      n1, n2 = compare[b][o][0], compare[b][o][1]
      t1, t2 = groups[b][n1], groups[b][n2]
      stat, p = ttest_ind(this_group[t1], this_group[t2])
      if p > 0.05: continue
      if sig > 0: high = high+diff*16
      li = plt.plot([x[b][n1], x[b][n1], x[b][n2], x[b][n2]], [high-diff, high, high, high-diff], color='k')
      string = '*'
      if p <= 0.01: string = '**'
      if p <= 0.005: string = '***'
      tx = plt.text(np.mean([x[b][n1], x[b][n2]]), high-diff*4, string, va='bottom', ha='center', fontsize=10)
      if b == 1: sig += 1
    yl = plt.ylim([low,high+span*0.2])
  axes[0].set_ylabel(a_div_labels[a], fontweight='bold')
  if a == 0:
    axes[0].set_title('Treatment', fontweight='bold')
    axes[1].set_title('Soil Horizon', fontweight='bold')
    axes[2].set_title('Treatment at each Soil Horizon', fontweight='bold')

plt.subplots_adjust(wspace=1.4)
plt.savefig(folder+'robyn_analysis/figures/alpha_diversity_16S.png', dpi=600, bbox_inches='tight')
```

ITS:
```{python}
#Treatment, Horizon, Treatment and horizon #2, 3, 6
ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rare_ITS.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_ITS.csv', index_col=0, header=0)
groups = [['Control', 'Treatment'], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon'], ['Control_Upper Forest Floor', 'Treatment_Upper Forest Floor', 'Control_Lower Forest Floor', 'Treatment_Lower Forest Floor', 'Control_Upper B Horizon', 'Treatment_Upper B Horizon']]
color_dict = {'Control':'#16A085', 'Treatment':'#F1C40F', 'Upper Forest Floor':'#E74C3C', 'Lower Forest Floor':'#8E44AD', 'Upper B Horizon':'#3498DB'}
colors = [[color_dict['Control'], color_dict['Treatment']], [color_dict['Upper Forest Floor'], color_dict['Lower Forest Floor'], color_dict['Upper B Horizon']], [color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment']]]
x_labs = [['Control', 'Treatment'], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon'], ['Control', 'Treatment', 'Control', 'Treatment', 'Control', 'Treatment']]
x = [[0,1], [0,1,2], [0,1,2.5,3.5,5,6]]
compare = [[[0,1]], [[0,1], [0,2], [1,2]], [[0,1], [2,3], [4,5]]]
x_locs_hor, x_labs_hor = [0.5, 3, 5.5], groups[1]

a_div_measures = ['observed_otus', 'chao1', 'shannon', 'simpson']
a_div_labels = ['Number of ASVs', 'Chao1 richness', 'Shannon diversity', "Simpson's diversity"]
fig = plt.figure(figsize=(10,10))
for a in range(len(a_div_measures)):
  axes = [plt.subplot2grid((len(a_div_measures),11), (a,0), colspan=2), plt.subplot2grid((len(a_div_measures),11), (a,2), colspan=3), plt.subplot2grid((len(a_div_measures),11), (a,5), colspan=6)]
  if a_div_measures[a] != 'faith_pd': alpha_div = alpha_diversity(a_div_measures[a], ft.transpose())
  else: alpha_div = alpha_diversity(a_div_measures[a], ft.transpose(), otu_ids=ft.index.values, tree=tree, validate=False)
  alpha_div = alpha_div.to_frame().rename(columns={0:a_div_measures[a]})
  alpha_div.index = ft.columns
  for b in range(len(groups)):
    plt.sca(axes[b])
    this_group = {}
    for c in range(len(groups[b])): this_group[groups[b][c]] = []
    for sample in alpha_div.index:
      if b == 0: md_group = md.loc[sample, 'Treatment'].strip()
      elif b == 1: md_group = md.loc[sample, 'Soil_Horizon'].strip()
      else: md_group = md.loc[sample, 'Treatment'].strip()+'_'+md.loc[sample, 'Soil_Horizon'].strip()
      this_group[md_group].append(alpha_div.loc[sample, a_div_measures[a]])
    for d in range(len(groups[b])):
      box = axes[b].boxplot(this_group[groups[b][d]], positions=[x[b][d]], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      scat = axes[b].scatter(np.random.normal(x[b][d], scale=0.075, size=len(this_group[groups[b][d]])), this_group[groups[b][d]], color=colors[b][d], alpha=0.5, edgecolors='gray')
    if a < len(a_div_measures)-1: ti = plt.xticks(x[b], [])
    else: 
      ti = plt.xticks(x[b], x_labs[b], rotation=90)
      if b == 2:
        for e in range(len(x_locs_hor)):
          xl = plt.text(x_locs_hor[e], -0.55, x_labs_hor[e], ha='center', va='top')
    high, low = float(axes[b].get_ylim()[1]), float(axes[b].get_ylim()[0])
    span = high-low
    diff = span*0.01
    high = high+diff*8
    sig = 0
    for o in range(len(compare[b])):
      n1, n2 = compare[b][o][0], compare[b][o][1]
      t1, t2 = groups[b][n1], groups[b][n2]
      stat, p = ttest_ind(this_group[t1], this_group[t2])
      if p > 0.05: continue
      if sig > 0: high = high+diff*16
      li = plt.plot([x[b][n1], x[b][n1], x[b][n2], x[b][n2]], [high-diff, high, high, high-diff], color='k')
      string = '*'
      if p <= 0.01: string = '**'
      if p <= 0.005: string = '***'
      tx = plt.text(np.mean([x[b][n1], x[b][n2]]), high-diff*4, string, va='bottom', ha='center', fontsize=10)
      if b == 1: sig += 1
    yl = plt.ylim([low,high+span*0.2])
  axes[0].set_ylabel(a_div_labels[a], fontweight='bold')
  if a == 0:
    axes[0].set_title('Treatment', fontweight='bold')
    axes[1].set_title('Soil Horizon', fontweight='bold')
    axes[2].set_title('Treatment at each Soil Horizon', fontweight='bold')

plt.subplots_adjust(wspace=1.4)
plt.savefig(folder+'robyn_analysis/figures/alpha_diversity_ITS.png', dpi=600, bbox_inches='tight')
```

# PCoA

```{python}
color_dict = {'Control':'#16A085', 'Treatment':'#F1C40F', 'Upper Forest Floor':'#E74C3C', 'Lower Forest Floor':'#8E44AD', 'Upper B Horizon':'#3498DB'}
shape_dict = {'Control':'o', 'Treatment':'^', 'Upper Forest Floor':'o', 'Lower Forest Floor':'^', 'Upper B Horizon':'p'}
line_dict = {'Control':'-', 'Treatment':'--', 'Upper Forest Floor':'-', 'Lower Forest Floor':'--', 'Upper B Horizon':'-.'}
stats_labs = ['sample_data(ps)$Treatment', 'sample_data(ps)$Soil_Horizon', 'sample_data(ps)$Treatment:sample_data(ps)$Soil_Horizon']
stats_text = ['Treatment', 'Soil Horizon', 'Treatment $x$ Soil Horizon']
color_by_treat = True

def plot_pcoa(name, ax):
  plt.sca(ax)
  distance = pd.read_csv(folder+'robyn_analysis/distances/'+name+'.csv', index_col=0, header=0)
  stats = pd.read_csv(folder+'robyn_analysis/stats_tests/adonis_'+name+'.csv', index_col=0, header=0)
  md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_'+name.split('_')[0]+'.csv', index_col=0, header=0)
  pcoa_results = ordination.pcoa(distance)
  PC1, PC2 = pcoa_results.samples.loc[:, 'PC1'].values, pcoa_results.samples.loc[:, 'PC2'].values
  prop_explain1, prop_explain2 = pcoa_results.proportion_explained[0], pcoa_results.proportion_explained[1]
  groups_x, groups_y = {}, {}
  for a in range(len(distance.index)):
    hor, treat = md.loc[distance.index[a], 'Soil_Horizon'].strip(), md.loc[distance.index[a], 'Treatment'].strip()
    if color_by_treat: color, shape = color_dict[treat], shape_dict[hor]
    else: color, shape = color_dict[hor], shape_dict[treat]
    group = hor+'|'+treat
    plt.scatter(PC1[a], PC2[a], marker=shape, color=color, edgecolor='gray')
    if group in groups_x:
      groups_x[group].append(PC1[a]), groups_y[group].append(PC2[a])
    else:
      groups_x[group] = [PC1[a]]
      groups_y[group] = [PC2[a]]
  lines, colors = [], []
  for group in groups_x:
    [hor, treat] = group.split('|')
    if color_by_treat: 
      color, line = color_dict[treat], line_dict[hor]
      lines.append(hor), colors.append(treat)
    else: 
      color, line = color_dict[hor], line_dict[treat]
      lines.append(treat), colors.append(hor)
    confidence_ellipse(groups_x[group], groups_y[group], ax, facecolor=color, alpha=0.1)
    confidence_ellipse(groups_x[group], groups_y[group], ax, edgecolor=color, linestyle=line, alpha=0.5)
  lines = list(set(lines))
  colors = list(set(colors))
  xl = plt.xlabel('PCoA1 ('+str(round(prop_explain1*100, 3))+'%)')
  yl = plt.ylabel('PCoA2 ('+str(round(prop_explain2*100, 3))+'%)')
  ti = plt.title(name, fontweight='bold')
  text = ''
  for l in range(len(stats_labs)):
    r2 = stats.loc[stats_labs[l], 'R2']
    p = stats.loc[stats_labs[l], 'Pr(>F)']
    text += stats_text[l]+': $R^{2}$='+str(round(r2,3))+', $p$='+str(round(p,3))
    if l < 2: text += '\n'
  anchored_text = AnchoredText(text, loc='lower right', prop=dict(size=8))
  anchored_text.patch.set_boxstyle("round,pad=0.,rounding_size=0.2")
  at = ax.add_artist(anchored_text)
  handles=[Line2D([0], [0], marker='s', color='w', label=name, markerfacecolor=color_dict[name], markersize=8) for name in colors]
  for name in lines:
    handles.append(Line2D([0], [0], marker=shape_dict[name], color='w', label=name, markerfacecolor='k', markersize=8))
    handles.append(Line2D([0,0.5], [0,0], linestyle=line_dict[name], color='k', label=name))
  lg = plt.legend(handles=handles, loc='lower left', fontsize=8)
  return pcoa_results.proportion_explained

finished = True
```

```{python}
names = ['16S_philr', '16S_rclr_euclidean', '16S_relabun_braycurtis', '16S_relabun_unweightedunifrac', '16S_relabun_weightedunifrac', 'ITS_rclr_euclidean', 'ITS_relabun_braycurtis']
fig = plt.figure(figsize=(20,20))

for n in range(len(names)):
  #if n > 0: continue
  ax1 = plt.subplot(3,3,n+1)
  prop = plot_pcoa(names[n], ax1)


plt.savefig(folder+'robyn_analysis/figures/beta_all_color_treatment.png', dpi=600, bbox_inches='tight')
#finished = True
```

# Alpha and beta for paper

```{python}
fig = plt.figure(figsize=(15,10))
ax1 = plt.subplot2grid((6,4),(0,0), colspan=2, rowspan=2)
ax2 = plt.subplot2grid((6,4),(0,2), colspan=2, rowspan=2)
ax3 = plt.subplot2grid((6,4),(2,0), colspan=2, rowspan=3)
ax4 = plt.subplot2grid((6,4),(2,2), colspan=2, rowspan=3)

axes, names, titles, subplot_labels, ylab = [ax3, ax4], ['16S_relabun_weightedunifrac', 'ITS_relabun_braycurtis'], ['Weighted UniFrac distance', 'Bray-Curtis dissimilarity'], ['C', 'D'], 'Beta diversity'
color_by_treat = True

for n in range(len(names)):
  prop = plot_pcoa(names[n], axes[n])
  ti = axes[n].set_title(titles[n], fontweight='bold')
  ti = axes[n].set_title(subplot_labels[n], fontweight='bold', loc='left')
  if n == 0: tx = axes[n].text(-0.2, 0.5, ylab, ha='center', va='center', rotation=90, fontweight='bold', fontsize=16, transform=axes[n].transAxes)
  
axes, amplicons, diversity, titles, subplot_labels, overall_titles, ylab = [ax1, ax2], ['16S', 'ITS'], ['faith_pd', 'simpson'], ["Faith's phylogenetic diversity", "Simpson's diversity"], ['A', 'B'], ['Bacteria and archaea (16S rRNA gene)', 'Fungi (ITS2 gene)'], 'Alpha diversity'
groups, x, compare, x_labs = ['Control_Upper Forest Floor', 'Treatment_Upper Forest Floor', 'Control_Lower Forest Floor', 'Treatment_Lower Forest Floor', 'Control_Upper B Horizon', 'Treatment_Upper B Horizon'], [0,1,2.5,3.5,5,6], [[0,1], [2,3], [4,5]], ['C', 'T', 'C', 'T', 'C', 'T']
colors = [color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment']]
x_locs_hor, x_labs_hor = [0.5, 3, 5.5], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']
for a in range(len(amplicons)):
  plt.sca(axes[a])
  ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rare_'+amplicons[a]+'.csv', index_col=0, header=0)
  md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_'+amplicons[a]+'.csv', index_col=0, header=0)
  if amplicons[a] == '16S': tree = read(folder+'robyn_analysis/tables_convert_from_maggie/tree_16S.tree', format="newick", into=TreeNode)
  if a == 0: tx = axes[a].text(-0.2, 0.5, ylab, ha='center', va='center', rotation=90, fontweight='bold', fontsize=16, transform=axes[a].transAxes)
  ti = axes[a].set_title(titles[a], fontweight='bold')
  ti = axes[a].set_title(subplot_labels[a], fontweight='bold', loc='left')
  tx = axes[a].text(0.5, 1.2, overall_titles[a], ha='center', va='center', fontweight='bold', fontsize=16, transform=axes[a].transAxes)
  #
  if diversity[a] != 'faith_pd': alpha_div = alpha_diversity(diversity[a], ft.transpose())
  else: alpha_div = alpha_diversity(diversity[a], ft.transpose(), otu_ids=ft.index.values, tree=tree, validate=False)
  alpha_div = alpha_div.to_frame().rename(columns={0:diversity[a]})
  alpha_div.index = ft.columns
  plt.sca(axes[a])
  this_group = {}
  for c in range(len(groups)): this_group[groups[c]] = []
  for sample in alpha_div.index:
    md_group = md.loc[sample, 'Treatment'].strip()+'_'+md.loc[sample, 'Soil_Horizon'].strip()
    this_group[md_group].append(alpha_div.loc[sample, diversity[a]])
  for d in range(len(groups)):
    box = axes[a].boxplot(this_group[groups[d]], positions=[x[d]], widths=0.6, showfliers=False)
    for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
    scat = axes[a].scatter(np.random.normal(x[d], scale=0.075, size=len(this_group[groups[d]])), this_group[groups[d]], color=colors[d], alpha=0.5, edgecolors='gray')
  ti = plt.xticks(x, x_labs)
  for e in range(len(x_locs_hor)):
    xl = axes[a].text(x_locs_hor[e], -0.55, x_labs_hor[e], ha='center', va='top')
  high, low = float(axes[a].get_ylim()[1]), float(axes[a].get_ylim()[0])
  span = high-low
  diff = span*0.01
  high = high+diff*8
  sig = 0
  for o in range(len(compare)):
      n1, n2 = compare[o][0], compare[o][1]
      t1, t2 = groups[n1], groups[n2]
      stat, p = ttest_ind(this_group[t1], this_group[t2])
      if p > 0.05: continue
      if sig > 0: high = high+diff*16
      li = axes[a].plot([x[n1], x[n1], x[n2], x[n2]], [high-diff, high, high, high-diff], color='k')
      string = '*'
      if p <= 0.01: string = '**'
      if p <= 0.005: string = '***'
      tx = axes[a].text(np.mean([x[n1], x[n2]]), high-diff*2, string, va='bottom', ha='center', fontsize=10)
  yl = axes[a].set_ylim([low,high+span*0.2])
  yl = axes[a].set_ylabel('Diversity index')

plt.subplots_adjust(wspace=0.5, hspace=1.3)
plt.savefig(folder+'robyn_analysis/figures/alpha_beta_combined.png', dpi=600, bbox_inches='tight')
plt.close()

```

Full:
```{python}
def plot_pcoa(name, ax, sample_group=''):
  plt.sca(ax)
  distance = pd.read_csv(folder+'robyn_analysis/distances/'+name+'.csv', index_col=0, header=0)
  stats = pd.read_csv(folder+'robyn_analysis/stats_tests/adonis_'+name+'.csv', index_col=0, header=0)
  md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_'+name.split('_')[0]+'.csv', index_col=0, header=0)
  if sample_group != '':
    samples_using = []
    for sample in distance.index:
      hor = md.loc[sample, 'Soil_Horizon'].strip()
      if hor == sample_group: samples_using.append(sample)
    distance = distance.loc[samples_using, samples_using]
  pcoa_results = ordination.pcoa(distance)
  PC1, PC2 = pcoa_results.samples.loc[:, 'PC1'].values, pcoa_results.samples.loc[:, 'PC2'].values
  prop_explain1, prop_explain2 = pcoa_results.proportion_explained[0], pcoa_results.proportion_explained[1]
  groups_x, groups_y = {}, {}
  for a in range(len(distance.index)):
    hor, treat = md.loc[distance.index[a], 'Soil_Horizon'].strip(), md.loc[distance.index[a], 'Treatment'].strip()
    if sample_group != '':
      if hor != sample_group: continue
      color, shape = color_dict[treat], shape_dict[hor]
    else:
      if color_by_treat: color, shape = color_dict[treat], shape_dict[hor]
      else: color, shape = color_dict[hor], shape_dict[treat]
    group = hor+'|'+treat
    plt.scatter(PC1[a], PC2[a], marker=shape, color=color, edgecolor='gray')
    if group in groups_x:
      groups_x[group].append(PC1[a]), groups_y[group].append(PC2[a])
    else:
      groups_x[group] = [PC1[a]]
      groups_y[group] = [PC2[a]]
  lines, colors = [], []
  for group in groups_x:
    [hor, treat] = group.split('|')
    if sample_group == '':
      if color_by_treat: 
        color, line = color_dict[treat], line_dict[hor]
        lines.append(hor), colors.append(treat)
      else: 
        color, line = color_dict[hor], line_dict[treat]
        lines.append(treat), colors.append(hor)
    else:
      color, line = color_dict[treat], line_dict[hor]
      lines.append(hor), colors.append(treat)
    confidence_ellipse(groups_x[group], groups_y[group], ax, facecolor=color, alpha=0.1)
    confidence_ellipse(groups_x[group], groups_y[group], ax, edgecolor=color, linestyle=line, alpha=0.5)
  lines = list(set(lines))
  colors = list(set(colors))
  xl = plt.xlabel('PCoA1 ('+str(round(prop_explain1*100, 3))+'%)')
  yl = plt.ylabel('PCoA2 ('+str(round(prop_explain2*100, 3))+'%)')
  ti = plt.title(name, fontweight='bold')
  if sample_group != '': return
  text = ''
  for l in range(len(stats_labs)):
    r2 = stats.loc[stats_labs[l], 'R2']
    p = stats.loc[stats_labs[l], 'Pr(>F)']
    text += stats_text[l]+': $R^{2}$='+str(round(r2,3))+', $p$='+str(round(p,3))
    if l < 2: text += '\n'
  anchored_text = AnchoredText(text, loc='lower right', prop=dict(size=8))
  anchored_text.patch.set_boxstyle("round,pad=0.,rounding_size=0.2")
  at = ax.add_artist(anchored_text)
  handles=[Line2D([0], [0], marker='s', color='w', label=name, markerfacecolor=color_dict[name], markersize=8) for name in colors]
  for name in lines:
    handles.append(Line2D([0], [0], marker=shape_dict[name], color='w', label=name, markerfacecolor='k', markersize=8))
    handles.append(Line2D([0,0.5], [0,0], linestyle=line_dict[name], color='k', label=name))
  lg = plt.legend(handles=handles, loc='lower left', fontsize=8)
  return pcoa_results.proportion_explained

fig = plt.figure(figsize=(15,15))
ax1_a = plt.subplot2grid((9,10),(0,0), colspan=2, rowspan=2)
ax1_b = plt.subplot2grid((9,10),(0,2), colspan=3, rowspan=2)
ax2_a = plt.subplot2grid((9,10),(0,5), colspan=2, rowspan=2)
ax2_b = plt.subplot2grid((9,10),(0,7), colspan=3, rowspan=2)
ax3 = plt.subplot2grid((9,6),(2,0), colspan=3, rowspan=2)
ax4 = plt.subplot2grid((9,6),(2,3), colspan=3, rowspan=2)
ax5 = plt.subplot2grid((9,6),(4,0), colspan=3, rowspan=3)
ax6 = plt.subplot2grid((9,6),(4,3), colspan=3, rowspan=3)
ax7_a = plt.subplot2grid((9,6),(7,0), colspan=1, rowspan=2)
ax7_b = plt.subplot2grid((9,6),(7,1), colspan=1, rowspan=2)
ax7_c = plt.subplot2grid((9,6),(7,2), colspan=1, rowspan=2)
ax8_a = plt.subplot2grid((9,6),(7,3), colspan=1, rowspan=2)
ax8_b = plt.subplot2grid((9,6),(7,4), colspan=1, rowspan=2)
ax8_c = plt.subplot2grid((9,6),(7,5), colspan=1, rowspan=2)

axes, names, titles, subplot_labels, ylab = [ax5, ax6], ['16S_relabun_weightedunifrac', 'ITS_relabun_braycurtis'], ['Weighted UniFrac distance', 'Bray-Curtis dissimilarity'], ['G', 'H'], ''
color_by_treat = False

for n in range(len(names)):
  prop = plot_pcoa(names[n], axes[n])
  ti = axes[n].set_title(titles[n], fontweight='bold')
  ti = axes[n].set_title(subplot_labels[n], fontweight='bold', loc='left')
  if n == 0: tx = axes[n].text(-0.2, 0.5, ylab, ha='center', va='center', rotation=90, fontweight='bold', fontsize=16, transform=axes[n].transAxes)

axes, names, titles, subplot_labels, ylab = [ax7_a, ax7_b, ax7_c, ax8_a, ax8_b, ax8_c], ['16S_relabun_weightedunifrac', '16S_relabun_weightedunifrac', '16S_relabun_weightedunifrac', 'ITS_relabun_braycurtis', 'ITS_relabun_braycurtis', 'ITS_relabun_braycurtis'], ['Weighted UniFrac distance', 'Weighted UniFrac distance', 'Weighted UniFrac distance', 'Bray-Curtis dissimilarity', 'Bray-Curtis dissimilarity', 'Bray-Curtis dissimilarity'], ['I', 'J', 'K', 'L', 'M', 'N'], ''
sample_groups = ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon', 'Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']
color_by_treat = False

for n in range(len(names)):
  prop = plot_pcoa(names[n], axes[n], sample_group=sample_groups[n])
  ti = axes[n].set_title(sample_groups[n].replace('Forest ', 'Forest\n').replace('B ', 'B\n'), fontweight='bold')
  ti = axes[n].set_title(subplot_labels[n], fontweight='bold', loc='left')
  if n == 0: tx = axes[n].text(-0.2, 0.5, ylab, ha='center', va='center', rotation=90, fontweight='bold', fontsize=16, transform=axes[n].transAxes)
  plt.sca(axes[n])
  xt = plt.xticks(fontsize=8)


axes, amplicons, diversity, titles, subplot_labels, overall_titles, ylab = [[ax1_a, ax1_b, ax3], [ax2_a, ax2_b, ax4]], ['16S', 'ITS'], ['faith_pd', 'simpson'], ["Faith's phylogenetic diversity", "Simpson's diversity"], [['A', 'B', 'E'], ['C', 'D', 'F']], ['Bacteria and archaea (16S rRNA gene)', 'Fungi (ITS2 gene)'], ''
groups = [['Control', 'Treatment'], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon'], ['Control_Upper Forest Floor', 'Treatment_Upper Forest Floor', 'Control_Lower Forest Floor', 'Treatment_Lower Forest Floor', 'Control_Upper B Horizon', 'Treatment_Upper B Horizon']]
x_labs = [['C', 'T'], ['Upper Forest\nFloor', 'Lower Forest\nFloor', 'Upper B\nHorizon'], ['C', 'T', 'C', 'T', 'C', 'T']]
x = [[0,1], [0,1,2], [0,1,2.5,3.5,5,6]]
#limits = [[0,1000], [0,1100], [4,9], [0.8,1.01], [25,160]]
compare = [[[0,1]], [[0,1], [0,2], [1,2]], [[0,1], [2,3], [4,5]]]
colors = [[color_dict['Control'], color_dict['Treatment']], [color_dict['Upper Forest Floor'], color_dict['Lower Forest Floor'], color_dict['Upper B Horizon']], [color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment'], color_dict['Control'], color_dict['Treatment']]]
x_locs_hor, x_labs_hor = [0.15, 0.5, 0.85], ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']
for a in range(len(amplicons)):
  for z in range(len(axes[a])):
    plt.sca(axes[a][z])
    ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rare_'+amplicons[a]+'.csv', index_col=0, header=0)
    md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_'+amplicons[a]+'.csv', index_col=0, header=0)
    if amplicons[a] == '16S': tree = read(folder+'robyn_analysis/tables_convert_from_maggie/tree_16S.tree', format="newick", into=TreeNode)
    if z < 2: ti = axes[a][z].set_title(titles[a].replace(' diversity', '\ndiversity'), fontweight='bold')
    else: ti = axes[a][z].set_title(titles[a], fontweight='bold')
    ti = axes[a][z].set_title(subplot_labels[a][z], fontweight='bold', loc='left')
    if z == 2: tx = axes[a][z].text(0.5, 2.8, overall_titles[a], ha='center', va='center', fontweight='bold', fontsize=16, transform=axes[a][z].transAxes)
    if diversity[a] != 'faith_pd': alpha_div = alpha_diversity(diversity[a], ft.transpose())
    else: alpha_div = alpha_diversity(diversity[a], ft.transpose(), otu_ids=ft.index.values, tree=tree, validate=False)
    alpha_div = alpha_div.to_frame().rename(columns={0:diversity[a]})
    alpha_div.index = ft.columns
    this_group = {}
    for c in range(len(groups[z])): this_group[groups[z][c]] = []
    for sample in alpha_div.index:
      if z == 0: md_group = md.loc[sample, 'Treatment'].strip()
      elif z == 1: md_group = md.loc[sample, 'Soil_Horizon'].strip()
      else: md_group = md.loc[sample, 'Treatment'].strip()+'_'+md.loc[sample, 'Soil_Horizon'].strip()
      this_group[md_group].append(alpha_div.loc[sample, diversity[a]])
    for d in range(len(groups[z])):
      box = axes[a][z].boxplot(this_group[groups[z][d]], positions=[x[z][d]], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      scat = axes[a][z].scatter(np.random.normal(x[z][d], scale=0.075, size=len(this_group[groups[z][d]])), this_group[groups[z][d]], color=colors[z][d], alpha=0.5, edgecolors='gray')
    ti = plt.xticks(x[z], x_labs[z])
    if z == 2:
      for e in range(len(x_locs_hor)):
        xl = axes[a][z].text(x_locs_hor[e], -0.15, x_labs_hor[e], ha='center', va='top', transform=axes[a][z].transAxes)
    high, low = float(axes[a][z].get_ylim()[1]), float(axes[a][z].get_ylim()[0])
    span = high-low
    diff = span*0.01
    high = high+diff*8
    sig = 0
    for o in range(len(compare[z])):
        n1, n2 = compare[z][o][0], compare[z][o][1]
        t1, t2 = groups[z][n1], groups[z][n2]
        stat, p = ttest_ind(this_group[t1], this_group[t2])
        if p > 0.05: continue
        if sig > 0: high = high+diff*16
        li = axes[a][z].plot([x[z][n1], x[z][n1], x[z][n2], x[z][n2]], [high-diff, high, high, high-diff], color='k')
        string = '*'
        if p <= 0.01: string = '**'
        if p <= 0.005: string = '***'
        tx = axes[a][z].text(np.mean([x[z][n1], x[z][n2]]), high-diff*2, string, va='bottom', ha='center', fontsize=10)
        if z == 1: sig += 1
    yl = axes[a][z].set_ylim([low,high+span*0.2])
    if a == 0 and z in [0, 2]: yl = axes[a][z].set_ylabel('Diversity index')
    

plt.subplots_adjust(wspace=0.6, hspace=1.7)
plt.savefig(folder+'robyn_analysis/figures/alpha_beta_combined_full.png', dpi=600, bbox_inches='tight')



```

#Beta-dispersion 16S
note: I had to re-run some things so things are hashed out that I did run, folder has been switching a bit 
Bray-Curtis on relative abundance:
```{R}
folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/'
ps = physeq_relabun_16S_new
distance <- phyloseq::distance(ps, method="bray", weighted=F)
bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both
anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_16S_relabun_braycurtis.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_16S_relabun_braycurtis.csv', sep=''))
write.csv(anova_both, paste(folder, 'stats_tests_mag/betadisp/anova_treat_hor_betadisp_16S_relabun_braycurtis.csv', sep=''))
permu_treat = permutest(bd_treat, pairwise = TRUE)
write.csv(permu_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/permu_treat_betadisp_16S_relabun_braycurtis.csv', sep=''))

#adding season
bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
permu_time
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_16S_relabun_braycurtis.csv', sep=''))

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_16S_relabun_braycurtis.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_16S_relabun_braycurtis.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_16S_relabun_braycurtis.csv', sep=''))
```

Weighted UniFrac on relative abundance:
```{R}
ps = physeq_relabun_16S_new
distance <- phyloseq::distance(ps, method="unifrac", weighted=T)
bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both
anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_16S_relabun_weightedunifrac.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_16S_relabun_weightedunifrac.csv', sep=''))
write.csv(anova_both, paste(folder, 'stats_tests_mag/betadisp/anova_treat_hor_betadisp_16S_relabun_weightedunifrac.csv', sep=''))
permu_treat = permutest(bd_treat, pairwise = TRUE)
write.csv(permu_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/permu_treat_betadisp_16S_relabun_weightedunifrac.csv', sep=''))

#adding season
bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_16S_relabun_weightedunifrac.csv', sep=''))
permu_time


#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_16S_relabun_weightedunifrac.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_16S_relabun_weightedunifrac.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_16S_relabun_weightedunifrac.csv', sep=''))
```

Unweighted UniFrac on relative abundance:
```{R}
ps = physeq_relabun_16S_new
distance <- phyloseq::distance(ps, method="unifrac", weighted=F)
bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both
anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))
write.csv(anova_both, paste(folder, 'stats_tests_mag/betadisp/anova_treat_hor_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))
permu_treat = permutest(bd_treat, pairwise = TRUE)
write.csv(permu_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/permu_treat_betadisp_16S_relabun_weightedunifrac.csv', sep=''))

bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_16S_relabun_unweightedunifrac.csv', sep=''))
```

Robust Aitchison's distance:
```{R}
ps = physeq_rclr_16S_new
distance <- phyloseq::distance(ps, method="euclidean", weighted=F)
bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both
anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_16S_rclr_euclidean.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_16S_rclr_euclidean.csv', sep=''))
write.csv(anova_both, paste(folder, 'stats_tests_mag/betadisp/anova_treat_hor_betadisp_16S_rclr_euclidean.csv', sep=''))
permu_treat = permutest(bd_treat, pairwise = TRUE)
write.csv(permu_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/permu_treat_betadisp_16S_rclr_euclidean.csv', sep=''))

bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_16S_rclr_euclidean.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_16S_rclr_euclidean.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_16S_rclr_euclidean.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_16S_rclr_euclidean.csv', sep=''))
```

PHILR distance:
```{R}
physeq_philr = physeq_16S_new
physeq_philr <- transform_sample_counts(physeq_philr, function(x) x+1)
phy_tree(physeq_philr) <- makeNodeLabel(phy_tree(physeq_philr), method="number", prefix='n')
otu.table <- t(otu_table(physeq_philr))
tree <- phy_tree(physeq_philr)
ps = physeq_philr
physeq.philr <- philr(otu.table, tree, part.weights='enorm.x.gm.counts', ilr.weights='blw.sqrt')
philr.dist <- dist(physeq.philr, method="euclidean")

bd_treat = betadisper(philr.dist, sample_data(ps)$Treatment)
bd_hor = betadisper(philr.dist, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(philr.dist, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both

anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_16S_philr.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_16S_philr.csv', sep=''))
write.csv(anova_both, paste(folder, 'stats_tests_mag/betadisp/anova_treat_hor_betadisp_16S_philr.csv', sep=''))

bd_time = betadisper(philr.dist, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_16S_16S_philr.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(philr.dist, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_16S_philr.csv', sep=''))

bd_hor_time = betadisper(philr.dist, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_16S_relabun_philr.csv', sep=''))

bd_treat_hor_time = betadisper(philr.dist, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_16S_philr.csv', sep=''))
```

# Betadisp ITS

Bray-Curtis relative abundance, robust Aitchison's distance. 

Bray-Curtis on relative abundance:
```{R}
ps = physeq_relabun_ITS_new
distance <- phyloseq::distance(ps, method="bray", weighted=F)

bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both

anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_ITS_relabun_braycurtis.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_ITS_relabun_braycurtis.csv', sep=''))
write.csv(anova_both, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_hor_betadisp_ITS_relabun_braycurtis.csv', sep=''))

bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_ITS_relabun_braycurtis.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_ITS_relabun_braycurtis.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_ITS_relabun_braycurtis.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_ITS_relabun_braycurtis.csv', sep=''))
```

Robust Aitchison's distance:
```{R}
ps = physeq_rclr_ITS_new
distance <- phyloseq::distance(ps, method="euclidean", weighted=F)

bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both

anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_ITS_rclr_euclidean.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_ITS_rclr_euclidean.csv', sep=''))
write.csv(anova_both, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_hor_betadisp_ITS_rclr_euclidean.csv', sep=''))

bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_ITS_rclr_euclidean.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_ITS_rclr_euclidean.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_ITS_rclr_euclidean.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_ITS_rclr_euclidean.csv', sep=''))
```

# Betadisp ITS genus

Bray-Curtis relative abundance, robust Aitchison's distance. 

Bray-Curtis on relative abundance:
```{R}
ps = physeq_relabun_ITS_new
rnk = "ta6"
ps = tax_glom(ps, taxrank=rnk, NArm=TRUE)
distance <- phyloseq::distance(ps, method="bray", weighted=F)

bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both

anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))
write.csv(anova_both, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_hor_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))

bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_ITS_genus_relabun_braycurtis.csv', sep=''))
```

Robust Aitchison's distance:
```{R}
ps = physeq_rclr_ITS_new
rnk = "ta6"
ps = tax_glom(ps, taxrank=rnk, NArm=TRUE)
distance <- phyloseq::distance(ps, method="euclidean", weighted=F)

bd_treat = betadisper(distance, sample_data(ps)$Treatment)
bd_hor = betadisper(distance, sample_data(ps)$Soil_Horizon)
bd_both = betadisper(distance, sample_data(ps)$Treatment_Horizon)
permu_treat = permutest(bd_treat, pairwise = TRUE)
permu_treat
permu_hor = permutest(bd_hor, pairwise = TRUE)
permu_hor
permu_both = permutest(bd_both, pairwise = TRUE)
permu_both

anova_treat = anova(bd_treat)
anova_hor = anova(bd_hor)
anova_both = anova(bd_both)
write.csv(anova_treat, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))
write.csv(anova_hor, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_hor_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))
write.csv(anova_both, paste(folder, 'robyn_analysis/stats_tests_mag/betadisp/anova_treat_hor_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))

bd_time = betadisper(distance, sample_data(ps)$Season)
permu_time = permutest(bd_time, pairwise = TRUE)
anova_time = anova(bd_time)
write.csv(anova_time, paste(folder, 'stats_tests_mag/betadisp/anova_time_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))
permu_time

#doing all the time  - make new folders!!
bd_treat_time = betadisper(distance, sample_data(ps)$Treatment_Season)
permu_treat_time = permutest(bd_treat_time, pairwise = TRUE)
permu_treat_time
anova_treat_time = anova(bd_treat_time)
write.csv(anova_treat_time, paste(folder, 'stats_tests_mag/betadisp/treat_time/anova_treat_time_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))

bd_hor_time = betadisper(distance, sample_data(ps)$Horizon_Season)
permu_hor_time = permutest(bd_hor_time, pairwise = TRUE)
permu_hor_time
anova_hor_time = anova(bd_hor_time)
write.csv(anova_hor_time, paste(folder, 'stats_tests_mag/betadisp/hor_time/anova_hor_time_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))

bd_treat_hor_time = betadisper(distance, sample_data(ps)$Treatment_Horizon_Season)
permu_treat_hor_time = permutest(bd_treat_hor_time, pairwise = TRUE)
permu_treat_hor_time
anova_treat_hor_time = anova(bd_treat_hor_time)
write.csv(anova_treat_hor_time, paste(folder, 'stats_tests_mag/betadisp/treat_hor_time/anova_treat_hor_time_betadisp_ITS_genus_rclr_euclidean.csv', sep=''))
```


# Differential abundance bacteria

##Ancom new (with ancombc)
###Upper Forest Floor
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol = 3
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)
ps.merged = tax_glom(physeq_rclr_16S, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper Forest Floor', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")


tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment", alpha=0.1)
w = ancom_out_up_ff$res$W
q = ancom_out_up_ff$res$q_val
p = ancom_out_up_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
print(w_tax)
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Taxa") #change the colnames in p
a_out_up_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = merge(a_out_up_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = a_out_up_ff[,-2] #remove the taxa column that came with w 
a_out_up_ff = a_out_up_ff[,-3] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_ff, paste(da_folder, "ancom_out_up_ff_new.csv", sep="")) #save the resulting table as a .csv file

#moving the taxa column & getting rid of ASV column 
a_out_up_ff <- read.csv(paste(da_folder, "ancom_out_up_ff_new.csv", sep="")) 
a_out_up_ff = a_out_up_ff %>% relocate(Taxa, .after = X) # move the taxa column 
a_out_up_ff = a_out_up_ff[,-1] # remove the ASV column 
write.csv(a_out_up_ff, row.names = FALSE, paste(da_folder, "ancom_out_up_ff_new_NEW.csv", sep=""))
```

###Lower Forest Floor
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol = 3
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)
ps.merged = tax_glom(physeq_rclr_16S, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Lower Forest Floor ', ps.merged)
#ps.merged.filter has all metadata but just for lower forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_low_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment", alpha=0.1)
w = ancom_out_low_ff$res$W
q = ancom_out_low_ff$res$q_val
p = ancom_out_low_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Taxa") #change the colnames in p
a_out_low_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = merge(a_out_low_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = a_out_low_ff[,-2] #remove the taxa column that came with w 
a_out_low_ff = a_out_low_ff[,-3] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_low_ff, paste(da_folder, "ancom_out_low_ff_new.csv", sep="")) #save the resulting table as a .csv file

a_out_low_ff <- read.csv(paste(da_folder, "ancom_out_low_ff_new.csv", sep="")) 
a_out_low_ff = a_out_low_ff %>% relocate(Taxa, .after = X) # move the taxa column 
a_out_low_ff = a_out_low_ff[,-1] # remove the ASV column 
write.csv(a_out_low_ff, row.names = FALSE, paste(da_folder, "ancom_out_low_ff_new_NEW.csv", sep=""))
```

###Upper B Horizon
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol = 3
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)
ps.merged = tax_glom(physeq_rclr_16S, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper B Horizon', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")


tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_b = ancombc(phyloseq=ps.rank.filter, formula="Treatment", alpha=0.1)
w = ancom_out_up_b$res$W
q = ancom_out_up_b$res$q_val
p = ancom_out_up_b$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
print(w_tax)
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Taxa") #change the colnames in p
a_out_up_b = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
a_out_up_b = merge(a_out_up_b, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
a_out_up_b = a_out_up_b[,-2] #remove the taxa column that came with w 
a_out_up_b = a_out_up_b[,-3] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_b, paste(da_folder, "ancom_out_up_b_new.csv", sep="")) #save the resulting table as a .csv file

a_out_up_b <- read.csv(paste(da_folder, "ancom_out_up_b_new.csv", sep="")) 
a_out_up_b = a_out_up_b %>% relocate(Taxa, .after = X) # move the taxa column 
a_out_up_b = a_out_up_b[,-1] # remove the ASV column 
write.csv(a_out_up_b, row.names = FALSE, paste(da_folder, "ancom_out_up_b_new_NEW.csv", sep=""))
```

##Maaslin2 (rarefied):

###Lower Forest Floor  
```{R Maaslin2}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol = 3
ps.rank = tax_glom(physeq_rare, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(
  feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/8.27_data/R_objects_new/Maaslin_new/Maaslin2_Low_FF", transform = "AST",
  fixed_effects = c("Groups"),
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)
```

###Upper Forest Floor
```{R Maaslin2_FF}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol = 3
# ps.rank = tax_glom(physeq_rare, taxrank=rnk, NArm=TRUE) 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')


md=data.frame(md)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(
  feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/8.27_data/R_objects_new/Maaslin_new/Maaslin2_Up_FF", transform = "AST",
  fixed_effects = c("Groups"),
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)

```

###Upper B Horizon
```{R Maaslin2_uB}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol = 3
#ps.rank = tax_glom(physeq_rare, taxrank=rnk, NArm=TRUE)  
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(
  feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/8.27_data/R_objects_new/Maaslin_new/Maaslin2_Upper_B", transform = "AST",
  fixed_effects = c("Groups"),
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)


```

##ALDEx2:
###Upper Forest Floor 
```{R ALDEx2_Forest_Floor}
rnk = "ta6"
numrnk = 6
mdcol = 3
ps.rank = tax_glom(physeq, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

results_Upper_Forest_Floor <- aldex(reads=ft, conditions = md[,1], mc.samples = 128, test="t", effect=TRUE,
                 include.sample.summary = FALSE, verbose=T, denom="all")
saveRDS(results_Upper_Forest_Floor, paste(folder, "R_objects_new/ALDEx_Upper_Forest_Floor.rds", sep=""))

```

###Lower Forest Floor
```{R ALDEx2_Humus}
rnk = "ta6"
numrnk = 6
mdcol = 3
#ps.rank = tax_glom(physeq, taxrank=rnk, NArm=TRUE) #need to have run it with aldex forest floor
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

results_Humus <- aldex(reads=ft, conditions = md[,1], mc.samples = 128, test="t", effect=TRUE,
                 include.sample.summary = FALSE, verbose=T, denom="all")
saveRDS(results_Humus, paste(folder, "R_objects_new/ALDEx_Lower_Forest_Floor.rds", sep=""))
```

###Upper B Horizon 
```{R ALDEx2_Upper_B}
rnk = "ta6"
numrnk = 6
mdcol = 3
#ps.rank = tax_glom(physeq, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

results_Upper_B <- aldex(reads=ft, conditions = md[,1], mc.samples = 128, test="t", effect=TRUE,
                 include.sample.summary = FALSE, verbose=T, denom="all")

saveRDS(results_Upper_B, paste(folder, "R_objects_new/ALDEx_Upper_B.rds", sep=""))
```
# Differential abundance fungi

###ANCOMBC 
####Upper forest floor 
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)
ps.merged = tax_glom(physeq_rclr_ITS, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper Forest Floor', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_up_ff$res$W
q = ancom_out_up_ff$res$q_val
p = ancom_out_up_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_up_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = merge(a_out_up_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = a_out_up_ff[,-4] #remove the taxa column that came with w 
a_out_up_ff = a_out_up_ff[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_ff, paste(da_folder, "ancom_out_up_ff_ITS_time.csv", sep="")) #save the resulting table as a .csv file
```

#### Lower Forest Floor
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)
ps.merged = tax_glom(physeq_rclr_ITS, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Lower Forest Floor ', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_low_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_low_ff$res$W
q = ancom_out_low_ff$res$q_val
p = ancom_out_low_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_low_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = merge(a_out_low_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = a_out_low_ff[,-4] #remove the taxa column that came with w 
a_out_low_ff = a_out_low_ff[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_low_ff, paste(da_folder, "ancom_out_low_ff_ITS_time.csv", sep="")) #save the resulting table as a .csv file
```


#### Upper B Horizon

Genus

```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)
ps.merged = tax_glom(physeq_rclr_ITS, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper B Horizon', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_b = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_up_b$res$W
q = ancom_out_up_b$res$q_val
p = ancom_out_up_b$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_up_b = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
a_out_up_b = merge(a_out_up_b, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
print(a_out_up_b)
a_out_up_b = a_out_up_b[,-4] #remove the taxa column that came with w 
a_out_up_b = a_out_up_b[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_b, paste(da_folder, "ancom_out_up_b_ITS_time.csv", sep="")) #save the resulting table as a .csv file
```

##Maaslin2 (rarefied):

###Upper Forest Floor
```{R Maaslin2_up_FF}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol = 4
ps.rank = tax_glom(physeq_rare, taxrank=rnk, NArm=TRUE) 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)

tax_table(ps.rank)

ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(
  feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/ITS_pros2/Maaslin2_Up_FF", transform = "AST",
  fixed_effects = c("Groups"),
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)

```

###Lower Forest Floor 
```{R Maaslin2_low_FF}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol = 4
#ps.rank = tax_glom(physeq_rare, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(
  feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/ITS_pros2/Maaslin2_Low_FF", transform = "AST",
  fixed_effects = c("Groups"),
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)


```
###Upper B Horizon
```{R Maaslin2_uB}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol = 4
#ps.rank = tax_glom(physeq_rare, taxrank=rnk, NArm=TRUE) if run alone, need this 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all <- Maaslin2(
  feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/ITS_pros2/Maaslin2_Upper_B", transform = "AST",
  fixed_effects = c("Groups"),
  standardize = FALSE, plot_heatmap = F, plot_scatter = F)


```

##ALDEx2:
###Upper Forest Floor 
```{R ALDEx2_Forest_Floor}
rnk = "ta6"
numrnk = 6
mdcol = 4
ps.rank = tax_glom(physeq, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

results_Upper_Forest_Floor <- aldex(reads=ft, conditions = md[,1], mc.samples = 128, test="t", effect=TRUE,
                 include.sample.summary = FALSE, verbose=T, denom="all")
saveRDS(results_Upper_Forest_Floor, paste(folder, "R_objects_ITS/ALDEx_Upper_Forest_Floor.rds", sep=""))
```

###Lower Forest Floor
```{R ALDEx2_Humus}
rnk = "ta6"
numrnk = 6
mdcol = 4
#ps.rank = tax_glom(physeq, taxrank=rnk, NArm=TRUE) 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

results_Lower_Forest_Floor <- aldex(reads=ft, conditions = md[,1], mc.samples = 128, test="t", effect=TRUE,
                 include.sample.summary = FALSE, verbose=T, denom="all")
saveRDS(results_Lower_Forest_Floor, paste(folder, "R_objects_ITS/ALDEx_Lower_Forest_Floor.rds", sep=""))
```

###Upper B Horizon 
```{R ALDEx2_Upper_B}
rnk = "ta6"
numrnk = 6
mdcol = 4
#ps.rank = tax_glom(physeq, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md = md[, mdcol]
md['Samples'] = rownames(md)
colnames(md) = c('Groups', 'Samples')

md=data.frame(md)

results_Upper_B <- aldex(reads=ft, conditions = md[,1], mc.samples = 128, test="t", effect=TRUE,
                 include.sample.summary = FALSE, verbose=T, denom="all")

saveRDS(results_Upper_B, paste(folder, "R_objects_ITS/ALDEx_Upper_B.rds", sep=""))
```



#Differnetial abudundance with sampling round
##Bacteria
###ANCOMBC 
####Upper forest floor 
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)
ps.merged = tax_glom(physeq_rclr_16S, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper Forest Floor', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_up_ff$res$W
q = ancom_out_up_ff$res$q_val
p = ancom_out_up_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
print(w_tax)
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_up_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = merge(a_out_up_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = a_out_up_ff[,-4] #remove the taxa column that came with w 
a_out_up_ff = a_out_up_ff[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_ff, paste(da_folder, "ancom_out_up_ff_time.csv", sep="")) #save the resulting table as a .csv file

#moving the taxa column & getting rid of ASV column 
a_out_up_ff <- read.csv(paste(da_folder, "ancom_out_up_ff_time.csv", sep="")) 
a_out_up_ff = a_out_up_ff %>% relocate(Taxa, .after = X) # move the taxa column 
a_out_up_ff = a_out_up_ff[,-1] # remove the ASV column 
write.csv(a_out_up_ff, row.names = FALSE, paste(da_folder, "ancom_out_up_ff_time_NEW.csv", sep=""))

#saveRDS(ancom_out_treat_hori_up_ff_new_time, paste(da_folder, "ancom_out_treat_hori_up_ff_new_time.rds", sep=""))
#up_for = readRDS(paste(da_folder, 'ancom_out_treat_hori_up_ff_new_time.rds', sep=''))$out
#write.csv(up_for, paste(da_folder, 'ancom_out_treat_hori_up_ff_new_time.csv', sep=''))

#process = feature_table_pre_process(ft, md1, 'Samples', 'Time Point', 'Treatment', lib_cut=10, neg_lb=TRUE)
#ancom_out_treat_hori_up_ff_new = ANCOM(process$feature_table, process$meta_data, process$structure_zeros, "Treatment", NULL)
#saveRDS(ancom_out_treat_hori_up_ff_new, paste(folder, "R_objects_new/DA_w_timepoint/ancom_out_treat_hori_up_ff_new.rds", sep=""))
#ancom_out_treat_hori_up_ff_new_time = ANCOM(process$feature_table, process$meta_data, process$structure_zeros, "Treatment", "Time Point")
#saveRDS(ancom_out_treat_hori_up_ff_new_time, paste(da_folder, "ancom_out_treat_hori_up_ff_new_time.rds", sep=""))
#up_for = readRDS(paste(da_folder, 'ancom_out_treat_hori_up_ff_new_time.rds', sep=''))$out
#write.csv(up_for, paste(da_folder, 'ancom_out_treat_hori_up_ff_new_time.csv', sep=''))

#a <- ifelse(ancom_out_treat_hori_up_ff$out$detected_0.9 == TRUE, "red", "black")

# (p <- plot_heatmap(ps.merged, "PCoA", "euclidean", "Treatment",rnk)) + theme(axis.text.y = element_text(colour = a))
```

#### Lower Forest Floor

Genus

```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)
ps.merged = tax_glom(physeq_rclr_16S, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Lower Forest Floor ', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_low_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_low_ff$res$W
q = ancom_out_low_ff$res$q_val
p = ancom_out_low_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_low_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = merge(a_out_low_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = a_out_low_ff[,-4] #remove the taxa column that came with w 
a_out_low_ff = a_out_low_ff[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_low_ff, paste(da_folder, "ancom_out_low_ff_time.csv", sep="")) #save the resulting table as a .csv file

#moving the taxa column & getting rid of ASV column 
a_out_low_ff <- read.csv(paste(da_folder, "ancom_out_low_ff_time.csv", sep="")) 
a_out_low_ff = a_out_low_ff %>% relocate(Taxa, .after = X) # move the taxa column 
a_out_low_ff = a_out_low_ff[,-1] # remove the ASV column 
write.csv(a_out_low_ff, row.names = FALSE, paste(da_folder, "ancom_out_low_ff_time_NEW.csv", sep=""))
```


#### Upper B Horizon

Genus

```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)
ps.merged = tax_glom(physeq_rclr_16S, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper B Horizon', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_b = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_up_b$res$W
q = ancom_out_up_b$res$q_val
p = ancom_out_up_b$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_up_b = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
a_out_up_b = merge(a_out_up_b, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
print(a_out_up_b)
a_out_up_b = a_out_up_b[,-4] #remove the taxa column that came with w 
a_out_up_b = a_out_up_b[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_b, paste(da_folder, "ancom_out_up_b_time.csv", sep="")) #save the resulting table as a .csv file

#moving the taxa column & getting rid of ASV column 
a_out_up_b <- read.csv(paste(da_folder, "ancom_out_up_b_time.csv", sep="")) 
a_out_up_b = a_out_up_b %>% relocate(Taxa, .after = X) # move the taxa column 
a_out_up_b = a_out_up_b[,-1] # remove the ASV column 
write.csv(a_out_up_b, row.names = FALSE, paste(da_folder, "ancom_out_up_b_time_NEW.csv", sep=""))
```


###Maaslin2 (rarefied):

####Upper Forest Floor
```{R Maaslin2_FF}
library(phyloseq)
library(readr)
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
mdcol_treat_time = 11
ps.rank = tax_glom(physeq_rare_16S_new, taxrank=rnk, NArm=TRUE) 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)

ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md3 = md[, mdcol_treat_time]
md1$Time_Point <- md2$Season
md1$Treatment_Time_Point <- md3$Treatment_Season
#colnames(md1) = c('Treatment', 'Samples', 'Time_Point')


md=data.frame(md1)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all_up_ff_time <- Maaslin2(feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/Maaslin_time/Maaslin2_Up_FF", transform = "AST", fixed_effects = c("Treatment", "Time_Point", "Treatment_Time_Point"), standardize = FALSE, plot_heatmap = F, plot_scatter = F)


# maaslin <-  read_tsv(paste(da_folder, "Maaslin_time/Maaslin2_Up_FF/all_results.tsv", sep="" ))
# maaslin_time = subset(maaslin, metadata == "Time_Point") #taking just the results for time point
# rownames(maaslin_time) <- NULL
# write.csv(maaslin_time, row.names= FALSE, paste(da_folder, "Maaslin_time_up_ff.csv", sep=""))
```

####Lower Forest Floor
```{R Maaslin2}
library(phyloseq)
library(readr)

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_rare_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all_low_ff_time <- Maaslin2(feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/Maaslin_time/Maaslin2_Low_FF", transform = "AST", fixed_effects = c("Treatment", "Time_Point"), standardize = FALSE, plot_heatmap = F, plot_scatter = F)
maaslin <-  read_tsv(paste(da_folder, "Maaslin_time/Maaslin2_Low_FF/all_results.tsv", sep="" ))
maaslin_time = subset(maaslin, metadata == "Time_Point") #taking just the results for time point
rownames(maaslin_time) <- NULL
write.csv(maaslin_time, row.names= FALSE, paste(da_folder, "Maaslin_time_low_ff.csv", sep=""))

```

####Upper B Horizon
```{R Maaslin2_uB}
library(phyloseq)
library(readr)

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_rare_16S, taxrank=rnk, NArm=TRUE) #if run alone, need this 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all_up_b_time <- Maaslin2(feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/Maaslin_time/Maaslin2_Up_B", transform = "AST", fixed_effects = c("Treatment", "Time_Point"), standardize = FALSE, plot_heatmap = F, plot_scatter = F)
maaslin <-  read_tsv(paste(da_folder, "Maaslin_time/Maaslin2_Up_B/all_results.tsv", sep="" ))
maaslin_time = subset(maaslin, metadata == "Time_Point") #taking just the results for time point
rownames(maaslin_time) <- NULL
write.csv(maaslin_time, row.names= FALSE, paste(da_folder, "Maaslin_time_up_b.csv", sep=""))
```

###ALDEx2:
####Upper Forest Floor 
```{R ALDEx2_Forest_Floor}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'
rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)


# ft = data.frame(otu_table(ps.rank.filter))
# #ft_names = rownames(ft)
# tax = tax_table(ps.rank.filter)
# rownames(ft) = tax[,numrnk]
# md = sample_data(ps.rank.filter)
# md = md[, mdcol]
# md['Samples'] = rownames(md)
# colnames(md) = c('Groups', 'Samples')

ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

matrixmodel = model.matrix(~Treatment * Time_Point, md)

results_Upper_Forest_Floor_clr <- aldex.clr(ft, matrixmodel, mc.samples = 128)
results_Upper_Forest_Floor_glm <- aldex.glm(results_Upper_Forest_Floor_clr, matrixmodel)
saveRDS(results_Upper_Forest_Floor_glm, paste(da_folder, "ALDEx_Upper_Forest_Floor_time.rds", sep=""))
ALDEx_Upper_Forest_Floor_time = readRDS(file =  paste(da_folder, "ALDEx_Upper_Forest_Floor_time.rds", sep=""))
write.csv(ALDEx_Upper_Forest_Floor_time, paste(da_folder, "ALDEx_Upper_Forest_Floor_time.csv", sep=""))
```

####Lower Forest Floor
```{R ALDEx2_Humus}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'
rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

matrixmodel = model.matrix(~Treatment * Time_Point, md)

results_Lower_Forest_Floor_clr <- aldex.clr(ft, matrixmodel, mc.samples = 128)
results_Lower_Forest_Floor_glm <- aldex.glm(results_Lower_Forest_Floor_clr, matrixmodel)
saveRDS(results_Lower_Forest_Floor_glm, paste(da_folder, "ALDEx_Lower_Forest_Floor_time.rds", sep=""))
ALDEx_Lower_Forest_Floor_time = readRDS(file =  paste(da_folder, "ALDEx_Lower_Forest_Floor_time.rds", sep=""))
write.csv(ALDEx_Lower_Forest_Floor_time, paste(da_folder, "ALDEx_Lower_Forest_Floor_time.csv", sep=""))
```

####Upper B Horizon 
```{R ALDEx2_Upper_B}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'
rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_16S, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


# ft = data.frame(otu_table(ps.rank.filter))
# #ft_names = rownames(ft)
# tax = tax_table(ps.rank.filter)
# rownames(ft) = tax[,numrnk]
# md = sample_data(ps.rank.filter)
# md = md[, mdcol]
# md['Samples'] = rownames(md)
# colnames(md) = c('Groups', 'Samples')

ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

matrixmodel = model.matrix(~Treatment * Time_Point, md)

results_Upper_B_Hoz_clr <- aldex.clr(ft, matrixmodel, mc.samples = 128)
results_Upper_B_Hoz_glm <- aldex.glm(results_Upper_B_Hoz_clr, matrixmodel)
saveRDS(results_Upper_B_Hoz_glm, paste(da_folder, "ALDEx_Upper_B_Hoz_time.rds", sep=""))
ALDEx_Upper_B_Hoz_time = readRDS(file =  paste(da_folder, "ALDEx_Upper_B_Hoz_time.rds", sep=""))
write.csv(ALDEx_Upper_B_Hoz_time, paste(da_folder, "ALDEx_Upper_B_Hoz_time.csv", sep=""))
```

##Fungi
###ANCOMBC 
####Upper forest floor 
```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)
ps.merged = tax_glom(physeq_rclr_ITS, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper Forest Floor', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_up_ff$res$W
q = ancom_out_up_ff$res$q_val
p = ancom_out_up_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_up_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = merge(a_out_up_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_ff) = rownames(w) #rename the rows
a_out_up_ff = a_out_up_ff[,-1] #remove the duplicated column
a_out_up_ff = a_out_up_ff[,-4] #remove the taxa column that came with w 
a_out_up_ff = a_out_up_ff[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_ff, paste(da_folder, "ancom_out_up_ff_ITS_time.csv", sep="")) #save the resulting table as a .csv file
```

#### Lower Forest Floor

Genus

```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)
ps.merged = tax_glom(physeq_rclr_ITS, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Lower Forest Floor ', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_low_ff = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_low_ff$res$W
q = ancom_out_low_ff$res$q_val
p = ancom_out_low_ff$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_low_ff = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = merge(a_out_low_ff, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_low_ff) = rownames(w) #rename the rows
a_out_low_ff = a_out_low_ff[,-1] #remove the duplicated column
a_out_low_ff = a_out_low_ff[,-4] #remove the taxa column that came with w 
a_out_low_ff = a_out_low_ff[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_low_ff, paste(da_folder, "ancom_out_low_ff_ITS_time.csv", sep="")) #save the resulting table as a .csv file
```


#### Upper B Horizon

Genus

```{R, results='hide', fig.keep='all', message=FALSE}
source(paste(folder, "ancom_v2.1.R", sep=""))

da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'

rnk = "ta6"
numrnk = 6
mdcol_treat = 3
mdcol_time = 9
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)
ps.merged = tax_glom(physeq_rclr_ITS, taxrank=rnk, NArm=TRUE)
ps.merged.filter = prune_samples(sample_data(ps.merged)$Soil_Horizon == 'Upper B Horizon', ps.merged)
#ps.merged.filter has all metadata but just for upper forest floor samples
ps.merged = merge_samples(ps.merged.filter, "Treatment")

#ft = otu_table(ps.rank.filter)
#ft_names = rownames(ft)
#tax = tax_table(ps.rank.filter)
#rownames(ft) = tax[,numrnk]
#md = sample_data(ps.rank.filter)
#md1 = md[, mdcol_time]
#md1['Samples'] = rownames(md1)
#md2 = md[, mdcol_treat]
#md1$treatment <- md2$Treatment
#colnames(md1) = c('Time Point', 'Samples', 'Treatment')

tax = tax_table(ps.rank.filter)
tax6 = tax[, numrnk] #ASV + tax6 names
tax6 = as.data.frame(tax6)
setDT(tax6, keep.rownames = "taxon")

ancom_out_up_b = ancombc(phyloseq=ps.rank.filter, formula="Treatment * Season", alpha=0.1)
w = ancom_out_up_b$res$W
q = ancom_out_up_b$res$q_val
p = ancom_out_up_b$res$p_val
w_tax = merge(w, tax6, by = "taxon")
q_tax = merge(q, tax6, by = "taxon")
p_tax = merge(p, tax6, by = "taxon")
rownames(w_tax) = w_tax[,1] #rename the rows in w
w = w_tax[,-c(1:2)] #remove columns 1-2 from w
rownames(q_tax) = q_tax[,1] #rename the rows in q
q = q_tax[,-c(1:2)] #remove columns 1-2 from q
rownames(p_tax) = p_tax[,1] #rename the rows in p
p = p_tax[,-c(1:2)] #remove columns 1-2 in p
colnames(w) = c("Treatment W", "Time_Point W", "Treatment_w_Time_Point W", "Taxa") #change the colnames in w
colnames(q) = c("Treatment q", "Time_Point q", "Treatment_w_Time_Point q", "Taxa") #change the colnames in q
colnames(p) = c("Treatment p", "Time_Point p", "Treatment_w_Time_Point p", "Taxa") #change the colnames in p
a_out_up_b = merge(w, q, by = 'row.names') #merge w and q based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
a_out_up_b = merge(a_out_up_b, p, by = 'row.names') #merge a_out (containing w and q) with p based on their row names
rownames(a_out_up_b) = rownames(w) #rename the rows
a_out_up_b = a_out_up_b[,-1] #remove the duplicated column
print(a_out_up_b)
a_out_up_b = a_out_up_b[,-4] #remove the taxa column that came with w 
a_out_up_b = a_out_up_b[,-7] #remove the taxa column that came with q - should only be left with one at the very end 
write.csv(a_out_up_b, paste(da_folder, "ancom_out_up_b_ITS_time.csv", sep="")) #save the resulting table as a .csv file
```


###Maaslin2 (rarefied):

####Upper Forest Floor
```{R Maaslin2_FF}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol_treat = 4
mdcol_time = 10
ps.rank = tax_glom(physeq_rare_ITS, taxrank=rnk, NArm=TRUE) 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)

ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all_up_ff_time <- Maaslin2(feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/Maaslin_time/Maaslin2_Up_FF_ITS_time", transform = "AST", fixed_effects = c("Treatment", "Time_Point"), standardize = FALSE, plot_heatmap = F, plot_scatter = F)


```

###Lower Forest Floor
```{R Maaslin2}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol_treat = 4
mdcol_time = 10
ps.rank = tax_glom(physeq_rare_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all_low_ff_time <- Maaslin2(feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/Maaslin_time/Maaslin2_Low_FF_ITS_time", transform = "AST", fixed_effects = c("Treatment", "Time_Point"), standardize = FALSE, plot_heatmap = F, plot_scatter = F)


```

####Upper B Horizon
```{R Maaslin2_uB}
library(phyloseq)

rnk = "ta6"
numrnk = 6
mdcol_treat = 4
mdcol_time = 10
#ps.rank = tax_glom(physeq_rare_ITS, taxrank=rnk, NArm=TRUE) if run alone, need this 
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

feat_table = data.frame(t(ft), check.rows = F, check.names = F, stringsAsFactors = F)
results_all_up_b_time <- Maaslin2(feat_table, md, "/Users/maggiehosmer/OneDrive - Dalhousie University/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/Maaslin_time/Maaslin2_Up_B_ITS_time", transform = "AST", fixed_effects = c("Treatment", "Time_Point"), standardize = FALSE, plot_heatmap = F, plot_scatter = F)

```

###ALDEx2:
####Upper Forest Floor 
```{R ALDEx2_Forest_Floor}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'
rnk = "ta6"
numrnk = 6
mdcol_treat = 4
mdcol_time = 10
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper Forest Floor', ps.rank)


# ft = data.frame(otu_table(ps.rank.filter))
# #ft_names = rownames(ft)
# tax = tax_table(ps.rank.filter)
# rownames(ft) = tax[,numrnk]
# md = sample_data(ps.rank.filter)
# md = md[, mdcol]
# md['Samples'] = rownames(md)
# colnames(md) = c('Groups', 'Samples')

ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

matrixmodel = model.matrix(~Treatment * Time_Point, md)

results_Upper_Forest_Floor_clr <- aldex.clr(ft, matrixmodel, mc.samples = 128)
results_Upper_Forest_Floor_glm <- aldex.glm(results_Upper_Forest_Floor_clr, matrixmodel)
saveRDS(results_Upper_Forest_Floor_glm, paste(da_folder, "ALDEx_Upper_Forest_Floor_ITS_time.rds", sep=""))
ALDEx_Upper_Forest_Floor_time = readRDS(file =  paste(da_folder, "ALDEx_Upper_Forest_Floor_ITS_time.rds", sep=""))
write.csv(ALDEx_Upper_Forest_Floor_time, paste(da_folder, "ALDEx_Upper_Forest_Floor_ITS_time.csv", sep=""))
```

####Lower Forest Floor
```{R ALDEx2_Humus}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'
rnk = "ta6"
numrnk = 6
mdcol_treat = 4
mdcol_time = 10
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Lower Forest Floor ', ps.rank)


ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

matrixmodel = model.matrix(~Treatment * Time_Point, md)

results_Lower_Forest_Floor_clr <- aldex.clr(ft, matrixmodel, mc.samples = 128)
results_Lower_Forest_Floor_glm <- aldex.glm(results_Lower_Forest_Floor_clr, matrixmodel)
saveRDS(results_Lower_Forest_Floor_glm, paste(da_folder, "ALDEx_Lower_Forest_Floor_ITS_time.rds", sep=""))
ALDEx_Lower_Forest_Floor_time = readRDS(file =  paste(da_folder, "ALDEx_Lower_Forest_Floor_ITS_time.rds", sep=""))
write.csv(ALDEx_Lower_Forest_Floor_time, paste(da_folder, "ALDEx_Lower_Forest_Floor_ITS_time.csv", sep=""))
```

####Upper B Horizon 
```{R ALDEx2_Upper_B}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'
rnk = "ta6"
numrnk = 6
mdcol_treat = 4
mdcol_time = 10
ps.rank = tax_glom(physeq_ITS, taxrank=rnk, NArm=TRUE)
ps.rank.filter = prune_samples(sample_data(ps.rank)$Soil_Horizon == 'Upper B Horizon', ps.rank)


# ft = data.frame(otu_table(ps.rank.filter))
# #ft_names = rownames(ft)
# tax = tax_table(ps.rank.filter)
# rownames(ft) = tax[,numrnk]
# md = sample_data(ps.rank.filter)
# md = md[, mdcol]
# md['Samples'] = rownames(md)
# colnames(md) = c('Groups', 'Samples')

ft = data.frame(otu_table(ps.rank.filter))
ft_names = rownames(ft)
tax = tax_table(ps.rank.filter)
rownames(ft) = tax[,numrnk]
md = sample_data(ps.rank.filter)
md1 = md[, mdcol_treat]
md1['Samples'] = rownames(md1)
md2 = md[, mdcol_time]
md1$treatment <- md2$Season
colnames(md1) = c('Treatment', 'Samples', 'Time_Point')

md=data.frame(md1)

matrixmodel = model.matrix(~Treatment * Time_Point, md)

results_Upper_B_Hoz_clr <- aldex.clr(ft, matrixmodel, mc.samples = 128)
results_Upper_B_Hoz_glm <- aldex.glm(results_Upper_B_Hoz_clr, matrixmodel)
saveRDS(results_Upper_B_Hoz_glm, paste(da_folder, "ALDEx_Upper_B_Hoz_ITS_time.rds", sep=""))
ALDEx_Upper_B_Hoz_time = readRDS(file =  paste(da_folder, "ALDEx_Upper_B_Hoz_ITS_time.rds", sep=""))
write.csv(ALDEx_Upper_B_Hoz_time, paste(da_folder, "ALDEx_Upper_B_Hoz_ITS_time.csv", sep=""))
```



# Differential abundance bacteria

Re-filter ANCOM: don't think I need to do this 
```{R, eval=FALSE}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'
low_ff = readRDS(paste(da_folder, 'ancom_out_treat_hori_low_ff.rds', sep=''))$out
up_ff = readRDS(paste(da_folder, 'ancom_out_treat_hori_up_ff.rds', sep=''))$out
up_B = readRDS(paste(da_folder, 'ancom_out_treat_hori_uB.rds', sep=''))$out
write.csv(low_ff, paste(da_folder, 'ancom_low_ff.csv', sep=''))
write.csv(up_ff, paste(da_folder, 'ancom_up_ff.csv', sep=''))
write.csv(up_B, paste(da_folder, 'ancom_up_B.csv', sep=''))
```

Combine differential abundance files, being a bit less stringent this time:
```{python, eval=FALSE}
#Three circles showing median and median +/- standard deviation
da_folder = '/Users/robynwright/Dropbox/Langille_Lab_postdoc/Acid_rain_recovery/maggie_analysis_files/differential_abundance_16S/'
da_folder_new = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'
folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/'

# ancom = [pd.read_csv(da_folder+'ancom_low_ff.csv', index_col=1, header=0), pd.read_csv(da_folder+'ancom_up_ff.csv', index_col=1, header=0), pd.read_csv(da_folder+'ancom_up_B.csv', index_col=1, header=0)]
# names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
# for a in range(len(ancom)):
#   ancom[a] = ancom[a].loc[:, ['detected_0.8']].rename(columns={'detected_0.8':names[a]})
#   ancom[a][ancom[a] == True] = 1
#   ancom[a][ancom[a] == False] = 0
#   rename = {}
#   for row in ancom[a].index:
#     rename[row] = row.strip()
#   ancom[a] = ancom[a].rename(index=rename)
# ancom = pd.concat(ancom).fillna(value=0)
# ancom = ancom.groupby(by=ancom.index, axis=0).sum()
# ancom.to_csv(folder+'robyn_analysis/differential_abundance_intermediate/ancom_16S.csv')

ancom = [pd.read_csv(da_folder_new+'ancom_out_low_ff_new_NEW.csv', index_col=0, header=0), pd.read_csv(da_folder_new+'ancom_out_up_ff_new_NEW.csv', index_col=0, header=0), pd.read_csv(da_folder_new+'ancom_out_up_b_new_NEW.csv', index_col=0, header=0)]
names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
for a in range(len(ancom)):
  ancom[a] = ancom[a].loc[:, ['Treatment.q']].rename(columns={'Treatment.q':names[a]})
  rename = {}
  for row in ancom[a].index:
    if ancom[a].loc[row, names[a]] <= 0.1: ancom[a].loc[row, names[a]] = 1 #changed from 0.1 to 0.2
    else: ancom[a].loc[row, names[a]] = 0
    rename[row] = row.strip()
  ancom[a] = ancom[a].rename(index=rename)
ancom = pd.concat(ancom).fillna(value=0)
ancom = ancom.groupby(by=ancom.index, axis=0).sum()
ancom.to_csv(folder+'new_differential_intermediate/ancom_NEW_0.2_16S.csv') #very different from old!

aldex = [pd.read_csv(da_folder+'ALDEx_Lower_Forest_Floor.csv', index_col=0, header=0), pd.read_csv(da_folder+'ALDEx_Upper_Forest_Floor.csv', index_col=0, header=0), pd.read_csv(da_folder+'ALDEx_Upper_B.csv', index_col=0, header=0)]
for a in range(len(aldex)):
  aldex[a] = aldex[a].loc[:, ['wi.eBH']].rename(columns={'wi.eBH':names[a]})
  rename = {}
  for row in aldex[a].index:
    if aldex[a].loc[row, names[a]] <= 0.1: aldex[a].loc[row, names[a]] = 1
    else: aldex[a].loc[row, names[a]] = 0
    rename[row] = row.strip()
  aldex[a] = aldex[a].rename(index=rename)
aldex = pd.concat(aldex).fillna(value=0)
aldex = aldex.groupby(by=aldex.index, axis=0).sum()
aldex.to_csv(folder+'robyn_analysis/differential_abundance_intermediate/aldex_16S.csv')

maaslin = [pd.read_csv(da_folder+'Maaslin_new/Maaslin2_Low_FF/all_results.tsv', index_col=0, header=0, sep='\t'), pd.read_csv(da_folder+'Maaslin_new/Maaslin2_Up_FF/all_results.tsv', index_col=0, header=0, sep='\t'), pd.read_csv(da_folder+'Maaslin_new/Maaslin2_Upper_B/all_results.tsv', index_col=0, header=0, sep='\t')]
for a in range(len(maaslin)):
  maaslin[a] = maaslin[a].loc[:, ['qval']].rename(columns={'qval':names[a]})
  rename = {}
  for row in maaslin[a].index:
    if maaslin[a].loc[row, names[a]] <= 0.1: maaslin[a].loc[row, names[a]] = 1
    else: maaslin[a].loc[row, names[a]] = 0
    rename[row] = row.replace('X.', '')
  maaslin[a] = maaslin[a].rename(index=rename)
maaslin = pd.concat(maaslin).fillna(value=0)
maaslin = maaslin.groupby(by=maaslin.index, axis=0).sum()
maaslin.to_csv(folder+'robyn_analysis/differential_abundance_intermediate/maaslin_16S.csv')

#when I am recombing the files 
ancom = pd.read_csv(folder+'new_differential_intermediate/ancom_NEW_16S.csv', index_col=0, header=0)
aldex = pd.read_csv(folder+'differential_abundance_intermediate/aldex_16S.csv', index_col=0, header=0)
maaslin = pd.read_csv(folder+'differential_abundance_intermediate/maaslin_16S.csv', index_col=0, header=0)

all_da = pd.concat([ancom, aldex, maaslin]).fillna(value=0)
all_da = all_da.groupby(by=all_da.index, axis=0).sum()
all_da.to_csv(folder+'new_differential_intermediate/all_da_16S_NEW.csv')
```


Get files, make dictionaries to rename genera and rename samples and then take only the top taxa:
```{python, eval=FALSE}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/analysis_files_mag/differential_abundance_16S/'
# tree_file = folder+'tree_treatment_horizon_filtered.tree'
# tree = Phylo.read(tree_file, "newick")

ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_16S.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_16S.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_16S.csv', index_col=0, header=0)

genus_match, genus_rename_asv, genus_rename_genus, genus_to_asv = {}, {}, {}, {}
for row in tax.index:
  genus = tax.loc[row, 'ta6'].strip()
  clss = tax.loc[row, 'ta3']
  genus_match[row] = genus
  genus_class = str(genus)
  if 'g__' not in genus_class: genus_class = ''
  genus_rename_asv[row] = clss+' '+genus_class
  genus_rename_genus[genus] = clss+' '+genus_class
  genus_to_asv[genus] = row

samples, samples_treat_loc_only, sample_new = {}, {}, {}
for col in ft.columns:
  samples[col] = md.loc[col, 'Treatment_Location_Horizon']
  new_sample = md.loc[col, 'Soil_Horizon'].strip()+' '+md.loc[col, 'Treatment'].strip()
  sample_new[col] = new_sample
  samples_treat_loc_only[md.loc[col, 'Treatment_Location_Horizon']] = new_sample
  
ft = ft.rename(columns=samples, index=genus_match)
ft = ft[ft.max(axis=1) > 0]
ft = ft.groupby(by=ft.index, axis=0).sum().groupby(by=ft.columns, axis=1).sum()
ft_ra = ft.copy(deep=True).divide(ft.sum(axis=0), axis=1).multiply(100)
X = ft.iloc[0:].values
ft_rclr = rclr(X)
ft_rclr = pd.DataFrame(ft_rclr, columns=ft.columns, index=ft.index.values).fillna(value=0)

#Investigate the top 25/30 taxa by relative abundance and rCLR:
top250_mean_ra, top250_sum_ra, top250_mean_rclr, top250_sum_rclr = [], [], [], []
ft_ra_copy = ft_ra.copy(deep=True)
ft_rclr_copy = ft_rclr.copy(deep=True)
ft_ra_copy['Mean'] = ft_ra_copy.mean(axis=1)
ft_ra_copy['Sum'] = ft_ra_copy.sum(axis=1)
ft_rclr_copy['Mean'] = ft_rclr_copy.mean(axis=1)
ft_rclr_copy['Sum'] = ft_rclr_copy.sum(axis=1)
ft_ra_copy = ft_ra_copy.sort_values(by=['Mean'], ascending=False)
top250_mean_ra = list(ft_ra_copy.head(245).index.values)
ft_ra_copy = ft_ra_copy.sort_values(by=['Sum'], ascending=False)
top250_sum_ra = list(ft_ra_copy.head(245).index.values)
ft_rclr_copy = ft_rclr_copy.sort_values(by=['Mean'], ascending=False)
top250_mean_rclr = list(ft_rclr_copy.head(245).index.values)
ft_rclr_copy = ft_rclr_copy.sort_values(by=['Sum'], ascending=False)
top250_sum_rclr = list(ft_rclr_copy.head(245).index.values)

all_top250 = [top250_mean_ra, top250_sum_ra, top250_mean_rclr, top250_sum_rclr]
all_gen = []
for a in range(len(all_top250)):
  all_top250[a] = sorted(all_top250[a])
  all_gen = all_gen+all_top250[a]
  
all_gen = list(set(all_gen))
#Taking top 25 genera by relative abundance/rCLR seems to pick up on totally different sets of taxa, with 46 total

#Filter the abundance files and tree file to have only these 46 genera:
ft_ra = ft_ra.loc[all_gen, :]
ft_rclr = ft_rclr.loc[all_gen, :]
ft_ra.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_ra_250_red_16S.csv')
ft_rclr.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_rclr_250_red_16S.csv')
asv_prune = [genus_to_asv[g] for g in all_gen]

tf = folder+'robyn_analysis/tables_convert_from_maggie/tree_16S.tree'
tree = Tree(tf, format=1)
tree_red = tree
tree_red.prune(asv_prune)
# for node in tree_red.traverse("postorder"):
#   if node.name in genus_match:
#     node.name = genus_match[node.name]
tree_red.ladderize()
tree_red.write(outfile=folder+'robyn_analysis/differential_abundance_intermediate_mag/reduced_tree_250_16S.tree', format=1)
```

Now make the plot!
```{python}
fig = plt.figure(figsize=(23,20))
ax_class = plt.subplot2grid((10,22),(0,1),rowspan=8, colspan=1, frameon=False)
ax_tree = plt.subplot2grid((10,22),(0,2),rowspan=8, colspan=8, frameon=False)
# ax_empty = plt.subplot2grid((10,10),(2,3),rowspan=8, colspan=2, frameon=False)
ax_ra = plt.subplot2grid((10,22),(0,10),rowspan=8, colspan=4)
ax_ra_colbar = plt.subplot2grid((30,44),(27,21),rowspan=1, colspan=6)
ax_rclr = plt.subplot2grid((10,22),(0,14),rowspan=8, colspan=4)
ax_rclr_colbar = plt.subplot2grid((30,44),(27,29),rowspan=1, colspan=6)
ax_da = plt.subplot2grid((10,22),(0,18),rowspan=8, colspan=3)
ax_da_colbar = plt.subplot2grid((30,44),(27,37),rowspan=1, colspan=4)

tree = Phylo.read(folder+'robyn_analysis/differential_abundance_intermediate_mag/reduced_tree_16S.tree', "newick")
leaves = draw_tree(tree, axes=ax_tree, end_same=True, plot_labels=False, fs=8)[1:]
plt.sca(ax_tree)
yl = plt.ylim([leaves[0][2]-0.5, leaves[-1][2]+0.5])
xl = plt.xlim(right=leaves[0][1]*2.2)
plt.sca(ax_class)
yl = plt.ylim([leaves[0][2]-0.5, leaves[-1][2]+0.5])
xl = plt.xticks([])
yl = plt.yticks([])
order = [genus_match[leaf[0]] for leaf in leaves]
names = [genus_rename_asv[leaf[0]] for leaf in leaves]
locs = [leaf[2] for leaf in leaves]
prev_class, start, class_count = '', leaves[0][2]-0.5, 17
handles = []
for l in range(len(names)):
  this_clss = names[l].split(' ')[1]
  if l == len(names)-1: end = True
  else: end = False
  if 'g__' in order[l]: 
    plot_name = order[l].replace('g__', '')
    if '_' in plot_name: 
      if 'Candidatus' in plot_name: plot_name = plot_name.replace('_', ' $')+'$'
      else: plot_name = plot_name.replace('_', ' ')
      plot_name = '  '+plot_name
    else: plot_name = '  $'+plot_name+'$'
  else: plot_name = '  '+order[l].replace('g__', '')
  tx = ax_tree.text(leaves[0][1], locs[l], plot_name, ha='left', va='center')
  if prev_class == '':
    prev_class = this_clss
    continue
  if prev_class != this_clss or end:
    if end: length = locs[l]+0.5-start
    else: length = locs[l]-0.5-start
    bar = ax_class.bar(0, length, bottom=start, edgecolor='k', alpha=0.4)
    bar2 = ax_tree.bar(0.02, length, bottom=start, alpha=0.15, width=5)
    text = ax_class.text(0, start+(length/2), str(class_count), ha='center', va='center')
    color = bar.patches[0].get_facecolor()
    handles.append(Patch(facecolor=color, edgecolor='k', label=str(class_count)+': '+prev_class))
    start = locs[l]-0.5
    class_count -= 1
  prev_class = this_clss
handles.reverse()
lg = ax_tree.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, -0.01), ncol=2)
ti = ax_class.set_title('A', loc='left', fontweight='bold', fontsize=16)

ft_ra = pd.read_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_ra_red_16S.csv', index_col=0, header=0)
ft_ra = ft_ra.loc[order, :].rename(columns=samples_treat_loc_only)
treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
ft_ra = ft_ra.groupby(by=ft_ra.columns, axis=1).mean().loc[:, treat_order]
ft_ra_norm = ft_ra.copy(deep=True).transpose()
ft_ra_norm = ft_ra_norm.divide(ft_ra_norm.max(axis=0), axis=1).transpose()
plt.sca(ax_ra)
pc = plt.pcolor(ft_ra_norm, cmap='RdPu', edgecolor='k')
yt = plt.yticks([])
for r in range(len(ft_ra.index)):
  for c in range(len(ft_ra.columns)):
    row, col = ft_ra.index[r], ft_ra.columns[c]
    if ft_ra_norm.loc[row, col] > 0.5: color = 'w'
    else: color = 'k'
    tx = ax_ra.text(c+0.5, r+0.5, str(round(ft_ra.loc[row, col], 2)), color=color, ha='center', va='center')
xt = plt.xticks([a+0.5 for a in range(len(ft_ra.columns))], [c.replace(' Control', '\nControl').replace(' Treatment', '\nTreatment') for c in ft_ra.columns], rotation=90)
#tt = ax_ra.xaxis.tick_top()
ti = ax_ra.set_title('Relative\nabundance (%)', fontweight='bold')
ti = ax_ra.set_title('B', loc='left', fontweight='bold', fontsize=16)

plt.sca(ax_ra_colbar)
cmap = mpl.cm.RdPu
norm = mpl.colors.Normalize(vmin=0, vmax=1)
cb = mpl.colorbar.ColorbarBase(ax_ra_colbar, cmap=cmap, norm=norm, orientation='horizontal')
xl = plt.title('Proportion of maximum\nfor genus', fontweight='bold')
    
ft_rclr = pd.read_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_rclr_red_16S.csv', index_col=0, header=0)
ft_rclr = ft_rclr.loc[order, :].rename(columns=samples_treat_loc_only)
treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
ft_rclr = ft_rclr.groupby(by=ft_rclr.columns, axis=1).mean().loc[:, treat_order]
plt.sca(ax_rclr)
pc = plt.pcolor(ft_rclr, cmap='bwr', edgecolor='k', vmin=-2, vmax=2)
yt = plt.yticks([])
for r in range(len(ft_rclr.index)):
  for c in range(len(ft_rclr.columns)):
    row, col = ft_rclr.index[r], ft_rclr.columns[c]
    if abs(ft_rclr.loc[row, col]) > 1: color = 'w'
    else: color = 'k'
    tx = ax_rclr.text(c+0.5, r+0.5, str(round(ft_rclr.loc[row, col], 2)), color=color, ha='center', va='center')
xt = plt.xticks([a+0.5 for a in range(len(ft_rclr.columns))], [c.replace(' Control', '\nControl').replace(' Treatment', '\nTreatment') for c in ft_rclr.columns], rotation=90)
#tt = ax_rclr.xaxis.tick_top()
ti = ax_rclr.set_title('rCLR relative\nabundance', fontweight='bold')
ti = ax_rclr.set_title('C', loc='left', fontweight='bold', fontsize=16)

plt.sca(ax_rclr_colbar)
cmap = mpl.cm.bwr
norm = mpl.colors.Normalize(vmin=-2, vmax=2)
cb = mpl.colorbar.ColorbarBase(ax_rclr_colbar, cmap=cmap, norm=norm, orientation='horizontal')
xl = plt.title('rCLR relative\nabundance', fontweight='bold')

da_int_folder = folder+'robyn_analysis/differential_abundance_intermediate_mag/'
all_da = pd.read_csv(da_int_folder+'all_da_16S.csv', index_col=0, header=0)
all_da = all_da.loc[order, ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']]
plt.sca(ax_da)
pc = plt.pcolor(all_da, cmap='Blues', edgecolor='k', vmin=0, vmax=3)
ti = ax_da.set_title('Differential\nabundance', fontweight='bold')
ti = ax_da.set_title('D', loc='left', fontweight='bold', fontsize=16)
yt = plt.yticks([])
xt = plt.xticks([a+0.5 for a in range(len(all_da.columns))], [c+'\nControl $vs$\nTreatment' for c in all_da.columns], rotation=90)
da_tests = [pd.read_csv(da_int_folder+'ancom_16S.csv', index_col=0, header=0), pd.read_csv(da_int_folder+'aldex_16S.csv', index_col=0, header=0), pd.read_csv(da_int_folder+'maaslin_16S.csv', index_col=0, header=0)]
x_loc, markers = [-0.25, 0, 0.25], ['o', 's', '^']
for r in range(len(all_da.index)):
  for c in range(len(all_da.columns)):
    row, col = all_da.index[r], all_da.columns[c]
    if all_da.loc[row, col] == 0: continue
    if all_da.loc[row, col] > 1: color = 'w'
    else: color = 'k'
    for t in range(len(da_tests)):
      if row not in da_tests[t].index: continue
      if da_tests[t].loc[row, col] > 0: 
        sc = ax_da.scatter(c+0.5+x_loc[t], r+0.5, marker=markers[t], color=color)

plt.sca(ax_da_colbar)
cmap_da = 'Blues'
norm = mpl.colors.Normalize(vmin=0, vmax=3)
fake_df = pd.DataFrame([[0, 1, 2, 3]])
pc = plt.pcolor(fake_df, edgecolor='k', cmap=cmap_da, vmin=0, vmax=3)
yt = plt.yticks([])
xt = plt.xticks([0.5, 1.5, 2.5, 3.5], [0, 1, 2, 3])
xl = plt.title('Number of tools finding\ngenus DA', fontweight='bold')

tests = ['ANCOM-II', 'ALDEx2', 'MaAsLin2']
handles = [Line2D([0], [0], marker=markers[m], color='w', label=tests[m], markerfacecolor='k', markersize=8) for m in range(len(markers))]
plt.sca(ax_da_colbar)
lg = plt.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, -1), ncol=2)

#plt.show()
plt.subplots_adjust(hspace=0.7)
plt.savefig(folder+'robyn_analysis/figures_mag/tree_heatmap_16S.png', dpi=600, bbox_inches='tight')
```

Now make boxplots with the top taxa:
```{python}
top_taxa = pd.read_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_ra_red_16S.csv', index_col=0, header=0).index.values
ft_ra = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_16S.csv', index_col=0, header=0)
ft_ra = ft_ra.rename(columns=sample_new, index=genus_match)
ft_ra = ft_ra.groupby(by=ft_ra.index, axis=0).sum()

ft_rclr = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rclr_16S.csv', index_col=0, header=0)
ft_rclr = ft_rclr.rename(columns=sample_new, index=genus_match)
ft_rclr = ft_rclr.groupby(by=ft_rclr.index, axis=0).sum()

treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
#treat_order = ['Control Upper Forest Floor', 'Treatment Upper Forest Floor', 'Control Lower Forest Floor', 'Treatment Lower Forest Floor', 'Control Upper B Horizon', 'Treatment Upper B Horizon']
color_dict = {'Control':'#16A085', 'Treatment':'#F1C40F', 'Upper Forest Floor':'#E74C3C', 'Lower Forest Floor':'#8E44AD', 'Upper B Horizon':'#3498DB'}
x_loc = [0, 1, 2.5, 3.5, 5, 6]
x_labs = ['Control', 'Treatment', 'Control', 'Treatment', 'Control', 'Treatment']
x_loc_hor = [0.15, 0.5, 0.85]
x_lab_hor = ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']

count = 0
for tax in top_taxa:
  #if tax != 'g__Gemmatimonas': continue
  fig = plt.figure(figsize=(12,7))
  ti = fig.suptitle(tax.replace('g__', ''), fontweight='bold')
  ax1, ax2 = plt.subplot(121), plt.subplot(122)
  axes, fts, titles = [ax1, ax2], [ft_ra, ft_rclr], ['Relative abundance (%)', 'rCLR relative abundance']
  for a in range(len(axes)):
    plt.sca(axes[a])
    if a == 1: li = axes[a].plot([-0.5, 6.5], [0, 0], 'k--')
    xl = plt.xlim([-0.5, 6.5])
    for b in range(len(treat_order)):
      vals = fts[a].loc[tax, treat_order[b]].values
      if 'Control' in treat_order[b]: color = color_dict['Control']
      else: color = color_dict['Treatment']
      sc = axes[a].scatter(np.random.normal(x_loc[b], 0.1, len(vals)), vals, color=color)
      box = axes[a].boxplot(vals, positions=[x_loc[b]], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      ti = axes[a].set_title(titles[a])
      if a == 0: yl = axes[a].set_ylabel('Abundance')
      ti = plt.xticks(x_loc, x_labs, rotation=90)
      for c in range(len(x_loc_hor)):
        tx = axes[a].text(x_loc_hor[c], -0.2, x_lab_hor[c], ha='center', va='center', transform=axes[a].transAxes)
  plt.savefig('/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/figures_mag/boxplots/16S_taxa_'+str(count+1)+'_'+tax+'.png', dpi=600, bbox_inches='tight')
  count += 1
  
finished = True
```


# Differential abundance bacteria with timepoint

Re-filter ANCOM:
```{R, eval=FALSE}
da_folder = '/Users/robynwright/Dropbox/Langille_Lab_postdoc/Acid_rain_recovery/maggie_analysis_files/differential_abundance_16S/'
low_ff = readRDS(paste(da_folder, 'ancom_out_treat_hori_low_ff.rds', sep=''))$out
up_ff = readRDS(paste(da_folder, 'ancom_out_treat_hori_up_ff.rds', sep=''))$out
up_B = readRDS(paste(da_folder, 'ancom_out_treat_hori_uB.rds', sep=''))$out
write.csv(low_ff, paste(da_folder, 'ancom_low_ff.csv', sep=''))
write.csv(up_ff, paste(da_folder, 'ancom_up_ff.csv', sep=''))
write.csv(up_B, paste(da_folder, 'ancom_up_B.csv', sep=''))
```

Combine differential abundance files, being a bit less stringent this time:
```{python, eval=FALSE}
#Three circles showing median and median +/- standard deviation
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/'
folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/'

ancom = [pd.read_csv(da_folder+'ancom_out_low_ff_time_NEW.csv', index_col=0, header=0), pd.read_csv(da_folder+'ancom_out_up_ff_time_NEW.csv', index_col=0, header=0), pd.read_csv(da_folder+'ancom_out_up_B_time_NEW.csv', index_col=0, header=0)]
names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
for a in range(len(ancom)):
  ancom[a] = ancom[a].loc[:, ['Time_Point.q']].rename(columns={'Time_Point.q':names[a]})
  rename = {}
  for row in ancom[a].index:
    if ancom[a].loc[row, names[a]] <= 0.1: ancom[a].loc[row, names[a]] = 1
    else: ancom[a].loc[row, names[a]] = 0
    rename[row] = row.strip()
  ancom[a] = ancom[a].rename(index=rename)
ancom = pd.concat(ancom).fillna(value=0)
ancom = ancom.groupby(by=ancom.index, axis=0).sum()
ancom.to_csv(folder+'new_differential_intermediate/ancom_time_16S.csv') #nothing found

aldex = [pd.read_csv(da_folder+'ALDEx_Lower_Forest_Floor_time.csv', index_col=0, header=0), pd.read_csv(da_folder+'ALDEx_Upper_Forest_Floor_time.csv', index_col=0, header=0), pd.read_csv(da_folder+'ALDEx_Upper_B_Hoz_time.csv', index_col=0, header=0)]
names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
for a in range(len(aldex)):
  aldex[a] = aldex[a].loc[:, ['Time_PointSummer:pval.holm']].rename(columns={'Time_PointSummer:pval.holm':names[a]})
  rename = {}
  for row in aldex[a].index:
    if aldex[a].loc[row, names[a]] <= 0.1: aldex[a].loc[row, names[a]] = 1 #p value not q value, I still think this is correct
    else: aldex[a].loc[row, names[a]] = 0
    rename[row] = row.strip()
  aldex[a] = aldex[a].rename(index=rename)
aldex = pd.concat(aldex).fillna(value=0)
aldex = aldex.groupby(by=aldex.index, axis=0).sum()
aldex.to_csv(folder+'new_differential_intermediate/aldex_time_16S.csv') #nothing found

maaslin = [pd.read_csv(da_folder+'Maaslin_time_low_ff.csv', index_col=0, header=0), pd.read_csv(da_folder+'Maaslin_time_up_ff.csv', index_col=0, header=0), pd.read_csv(da_folder+'Maaslin_time_up_b.csv', index_col=0, header=0)]
names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
for a in range(len(maaslin)):
  maaslin[a] = maaslin[a].loc[:, ['qval']].rename(columns={'qval':names[a]})
  rename = {}
  for row in maaslin[a].index:
    if maaslin[a].loc[row, names[a]] <= 0.1: maaslin[a].loc[row, names[a]] = 1
    else: maaslin[a].loc[row, names[a]] = 0
    rename[row] = row.replace('X.', '')
  maaslin[a] = maaslin[a].rename(index=rename)
maaslin = pd.concat(maaslin).fillna(value=0)
maaslin = maaslin.groupby(by=maaslin.index, axis=0).sum()
maaslin.to_csv(folder+'new_differential_intermediate/maaslin_time_16S.csv') 

all_da = pd.concat([ancom, aldex, maaslin]).fillna(value=0)
all_da = all_da.groupby(by=all_da.index, axis=0).sum()
all_da.to_csv(folder+'new_differential_intermediate/all_da_time_16S.csv')
```

Get files, make dictionaries to rename genera and rename samples and then take only the top taxa:didn't do 
```{python, eval=FALSE}
da_folder = '/Users/robynwright/Dropbox/Langille_Lab_postdoc/Acid_rain_recovery/maggie_analysis_files/differential_abundance_16S/'
# tree_file = folder+'tree_treatment_horizon_filtered.tree'
# tree = Phylo.read(tree_file, "newick")

ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_16S.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_16S.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_16S.csv', index_col=0, header=0)

genus_match, genus_rename_asv, genus_rename_genus, genus_to_asv = {}, {}, {}, {}
for row in tax.index:
  genus = tax.loc[row, 'ta6'].strip()
  clss = tax.loc[row, 'ta3']
  genus_match[row] = genus
  genus_class = str(genus)
  if 'g__' not in genus_class: genus_class = ''
  genus_rename_asv[row] = clss+' '+genus_class
  genus_rename_genus[genus] = clss+' '+genus_class
  genus_to_asv[genus] = row

samples, samples_treat_loc_only, sample_new = {}, {}, {}
for col in ft.columns:
  samples[col] = md.loc[col, 'Treatment_Location_Horizon']
  new_sample = md.loc[col, 'Soil_Horizon'].strip()+' '+md.loc[col, 'Treatment'].strip()
  sample_new[col] = new_sample
  samples_treat_loc_only[md.loc[col, 'Treatment_Location_Horizon']] = new_sample
  
ft = ft.rename(columns=samples, index=genus_match)
ft = ft[ft.max(axis=1) > 0]
ft = ft.groupby(by=ft.index, axis=0).sum().groupby(by=ft.columns, axis=1).sum()
ft_ra = ft.copy(deep=True).divide(ft.sum(axis=0), axis=1).multiply(100)
X = ft.iloc[0:].values
ft_rclr = rclr(X)
ft_rclr = pd.DataFrame(ft_rclr, columns=ft.columns, index=ft.index.values).fillna(value=0)

#Investigate the top 25/30 taxa by relative abundance and rCLR:
top30_mean_ra, top30_sum_ra, top30_mean_rclr, top30_sum_rclr = [], [], [], []
ft_ra_copy = ft_ra.copy(deep=True)
ft_rclr_copy = ft_rclr.copy(deep=True)
ft_ra_copy['Mean'] = ft_ra_copy.mean(axis=1)
ft_ra_copy['Sum'] = ft_ra_copy.sum(axis=1)
ft_rclr_copy['Mean'] = ft_rclr_copy.mean(axis=1)
ft_rclr_copy['Sum'] = ft_rclr_copy.sum(axis=1)
ft_ra_copy = ft_ra_copy.sort_values(by=['Mean'], ascending=False)
top30_mean_ra = list(ft_ra_copy.head(25).index.values)
ft_ra_copy = ft_ra_copy.sort_values(by=['Sum'], ascending=False)
top30_sum_ra = list(ft_ra_copy.head(25).index.values)
ft_rclr_copy = ft_rclr_copy.sort_values(by=['Mean'], ascending=False)
top30_mean_rclr = list(ft_rclr_copy.head(25).index.values)
ft_rclr_copy = ft_rclr_copy.sort_values(by=['Sum'], ascending=False)
top30_sum_rclr = list(ft_rclr_copy.head(25).index.values)

all_top30 = [top30_mean_ra, top30_sum_ra, top30_mean_rclr, top30_sum_rclr]
all_gen = []
for a in range(len(all_top30)):
  all_top30[a] = sorted(all_top30[a])
  all_gen = all_gen+all_top30[a]
  
all_gen = list(set(all_gen))
#Taking top 25 genera by relative abundance/rCLR seems to pick up on totally different sets of taxa, with 46 total

#Filter the abundance files and tree file to have only these 46 genera:
ft_ra = ft_ra.loc[all_gen, :]
ft_rclr = ft_rclr.loc[all_gen, :]
ft_ra.to_csv(folder+'robyn_analysis/differential_abundance_intermediate/ft_ra_red_16S.csv')
ft_rclr.to_csv(folder+'robyn_analysis/differential_abundance_intermediate/ft_rclr_red_16S.csv')
asv_prune = [genus_to_asv[g] for g in all_gen]

tf = folder+'robyn_analysis/tables_convert_from_maggie/tree_16S.tree'
tree = Tree(tf, format=1)
tree_red = tree
tree_red.prune(asv_prune)
# for node in tree_red.traverse("postorder"):
#   if node.name in genus_match:
#     node.name = genus_match[node.name]
tree_red.ladderize()
tree_red.write(outfile=folder+'robyn_analysis/differential_abundance_intermediate/reduced_tree_16S.tree', format=1)
```

# Differential abundance fungi

Re-filter ANCOM:
```{R}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/maggie_analysis_files/differential_abundance_ITS_mag/'
low_ff = readRDS(paste(da_folder, 'ancom_out_treat_hori_low_ff.rds', sep=''))$out
up_ff = readRDS(paste(da_folder, 'ancom_out_treat_hori_up_ff.rds', sep=''))$out
up_B = readRDS(paste(da_folder, 'ancom_out_treat_hori_uB.rds', sep=''))$out
write.csv(low_ff, paste(da_folder, 'ancom_low_ff.csv', sep=''))
write.csv(up_ff, paste(da_folder, 'ancom_up_ff.csv', sep=''))
write.csv(up_B, paste(da_folder, 'ancom_up_B.csv', sep=''))
```

Combine differential abundance files, being a bit less stringent this time:
```{python}
#Three circles showing median and median +/- standard deviation
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/maggie_analysis_files/differential_abundance_ITS_mag/'
da_folder_new = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/R_objects_new/DA_w_timepoint/fungi/'
folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/'

# ancom = [pd.read_csv(da_folder+'ancom_low_ff.csv', index_col=1, header=0), pd.read_csv(da_folder+'ancom_up_ff.csv', index_col=1, header=0), pd.read_csv(da_folder+'ancom_up_B.csv', index_col=1, header=0)]
# names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
# for a in range(len(ancom)):
#   ancom[a] = ancom[a].loc[:, ['detected_0.8']].rename(columns={'detected_0.8':names[a]})
#   ancom[a][ancom[a] == True] = 1
#   ancom[a][ancom[a] == False] = 0
#   rename = {}
#   for row in ancom[a].index:
#     rename[row] = row.strip()
#   ancom[a] = ancom[a].rename(index=rename)
# ancom = pd.concat(ancom).fillna(value=0)
# ancom = ancom.groupby(by=ancom.index, axis=0).sum()
# ancom.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ancom_ITS.csv')

ancom = [pd.read_csv(da_folder_new+'ancom_out_low_ff_ITS_new_NEW.csv', index_col=0, header=0), pd.read_csv(da_folder_new+'ancom_out_up_ff_ITS_new_NEW.csv', index_col=0, header=0), pd.read_csv(da_folder_new+'ancom_out_up_b_ITS_new_NEW.csv', index_col=0, header=0)]
names = ['Lower Forest Floor', 'Upper Forest Floor', 'Upper B Horizon']
for a in range(len(ancom)):
  ancom[a] = ancom[a].loc[:, ['Treatment.q']].rename(columns={'Treatment.q':names[a]})
  rename = {}
  for row in ancom[a].index:
    if ancom[a].loc[row, names[a]] <= 0.1: ancom[a].loc[row, names[a]] = 1 #changed from 0.1 to 0.2
    else: ancom[a].loc[row, names[a]] = 0
    rename[row] = row.strip()
  ancom[a] = ancom[a].rename(index=rename)
ancom = pd.concat(ancom).fillna(value=0)
ancom = ancom.groupby(by=ancom.index, axis=0).sum()
ancom.to_csv(folder+'new_differential_intermediate/ancom_NEW_0.1_ITS.csv') #very different from old!

aldex = [pd.read_csv(da_folder+'ALDEx_Lower_Forest_Floor.csv', index_col=0, header=0), pd.read_csv(da_folder+'ALDEx_Upper_Forest_Floor.csv', index_col=0, header=0), pd.read_csv(da_folder+'ALDEx_Upper_B.csv', index_col=0, header=0)]
for a in range(len(aldex)):
  aldex[a] = aldex[a].loc[:, ['wi.eBH']].rename(columns={'wi.eBH':names[a]})
  rename = {}
  for row in aldex[a].index:
    if aldex[a].loc[row, names[a]] <= 0.1: aldex[a].loc[row, names[a]] = 1
    else: aldex[a].loc[row, names[a]] = 0
    rename[row] = row.strip()
  aldex[a] = aldex[a].rename(index=rename)
aldex = pd.concat(aldex).fillna(value=0)
aldex = aldex.groupby(by=aldex.index, axis=0).sum()
aldex.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/aldex_ITS.csv')

maaslin = [pd.read_csv(da_folder+'Maaslin/Maaslin2_Low_FF/all_results.tsv', index_col=0, header=0, sep='\t'), pd.read_csv(da_folder+'Maaslin/Maaslin2_Up_FF/all_results.tsv', index_col=0, header=0, sep='\t'), pd.read_csv(da_folder+'Maaslin/Maaslin2_Upper_B/all_results.tsv', index_col=0, header=0, sep='\t')]
for a in range(len(maaslin)):
  maaslin[a] = maaslin[a].loc[:, ['qval']].rename(columns={'qval':names[a]})
  rename = {}
  for row in maaslin[a].index:
    if maaslin[a].loc[row, names[a]] <= 0.1: maaslin[a].loc[row, names[a]] = 1
    else: maaslin[a].loc[row, names[a]] = 0
    rename[row] = row.replace('X.', '')
  maaslin[a] = maaslin[a].rename(index=rename)
maaslin = pd.concat(maaslin).fillna(value=0)
maaslin = maaslin.groupby(by=maaslin.index, axis=0).sum()
maaslin.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/maaslin_ITS.csv')

#when I am recombing the files 
ancom = pd.read_csv(folder+'new_differential_intermediate/ancom_NEW_0.1_ITS.csv', index_col=0, header=0)
aldex = pd.read_csv(folder+'differential_abundance_intermediate/aldex_ITS.csv', index_col=0, header=0)
maaslin = pd.read_csv(folder+'differential_abundance_intermediate/maaslin_ITS.csv', index_col=0, header=0)

all_da = pd.concat([ancom, aldex, maaslin]).fillna(value=0)
all_da = all_da.groupby(by=all_da.index, axis=0).sum()
all_da.to_csv(folder+'new_differential_intermediate/all_da_ITS_NEW.csv')
```

Get files, make dictionaries to rename genera and rename samples and then take only the top taxa:
```{python, eval=FALSE}
da_folder = '/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/maggie_analysis_files/differential_abundance_ITS_mag/'
# tree_file = folder+'tree_treatment_horizon_filtered.tree'
# tree = Phylo.read(tree_file, "newick")

ft = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_ITS.csv', index_col=0, header=0)
tax = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/taxonomy_ITS.csv', index_col=0, header=0)
md = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/metadata_ITS.csv', index_col=0, header=0)

genus_match, genus_rename_asv, genus_rename_genus, genus_to_asv, full_tax = {}, {}, {}, {}, {}
for row in tax.index:
  genus = tax.loc[row, 'ta6'].strip()
  clss = tax.loc[row, 'ta3']
  genus_match[row] = genus
  genus_class = str(genus)
  if 'g__' not in genus_class: genus_class = ''
  genus_rename_asv[row] = clss+' '+genus_class
  genus_rename_genus[genus] = clss+' '+genus_class
  genus_to_asv[genus] = row
  full_tax[genus] = tax.loc[row, :].values

samples, samples_treat_loc_only, sample_new = {}, {}, {}
for col in ft.columns:
  samples[col] = md.loc[col, 'Treatment_Location_Horizon']
  new_sample = md.loc[col, 'Soil_Horizon'].strip()+' '+md.loc[col, 'Treatment'].strip()
  sample_new[col] = new_sample
  samples_treat_loc_only[md.loc[col, 'Treatment_Location_Horizon']] = new_sample
  
ft = ft.rename(columns=samples, index=genus_match)
ft = ft[ft.max(axis=1) > 0]
ft = ft.groupby(by=ft.index, axis=0).sum().groupby(by=ft.columns, axis=1).sum()
ft_ra = ft.copy(deep=True).divide(ft.sum(axis=0), axis=1).multiply(100)
X = ft.iloc[0:].values
ft_rclr = rclr(X)
ft_rclr = pd.DataFrame(ft_rclr, columns=ft.columns, index=ft.index.values).fillna(value=0)

#Investigate the top 25/30 taxa by relative abundance and rCLR:
top30_mean_ra, top30_sum_ra, top30_mean_rclr, top30_sum_rclr = [], [], [], []
ft_ra_copy = ft_ra.copy(deep=True)
ft_rclr_copy = ft_rclr.copy(deep=True)
ft_ra_copy['Mean'] = ft_ra_copy.mean(axis=1)
ft_ra_copy['Sum'] = ft_ra_copy.sum(axis=1)
ft_rclr_copy['Mean'] = ft_rclr_copy.mean(axis=1)
ft_rclr_copy['Sum'] = ft_rclr_copy.sum(axis=1)
ft_ra_copy = ft_ra_copy.sort_values(by=['Mean'], ascending=False)
top30_mean_ra = list(ft_ra_copy.head(25).index.values)
ft_ra_copy = ft_ra_copy.sort_values(by=['Sum'], ascending=False)
top30_sum_ra = list(ft_ra_copy.head(25).index.values)
ft_rclr_copy = ft_rclr_copy.sort_values(by=['Mean'], ascending=False)
top30_mean_rclr = list(ft_rclr_copy.head(25).index.values)
ft_rclr_copy = ft_rclr_copy.sort_values(by=['Sum'], ascending=False)
top30_sum_rclr = list(ft_rclr_copy.head(25).index.values)

all_top30 = [top30_mean_ra, top30_sum_ra, top30_mean_rclr, top30_sum_rclr]
all_gen = []
for a in range(len(all_top30)):
  all_top30[a] = sorted(all_top30[a])
  all_gen = all_gen+all_top30[a]
  
all_gen = list(set(all_gen))
#Taking top 25 genera by relative abundance/rCLR seems to pick up on totally different sets of taxa, with 44 total

#Filter the abundance files and tree file to have only these 46 genera:
ft_ra = ft_ra.loc[all_gen, :]
ft_rclr = ft_rclr.loc[all_gen, :]
ft_ra.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_ra_red_ITS.csv')
ft_rclr.to_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_rclr_red_ITS.csv')
```

Now make the plot!
```{python}
fig = plt.figure(figsize=(23,20))
ax_class = plt.subplot2grid((10,22),(0,7),rowspan=8, colspan=1, frameon=False)
ax_tree = plt.subplot2grid((10,22),(0,8),rowspan=8, colspan=2, frameon=False)
# ax_empty = plt.subplot2grid((10,10),(2,3),rowspan=8, colspan=2, frameon=False)
ax_ra = plt.subplot2grid((10,22),(0,10),rowspan=8, colspan=4)
ax_ra_colbar = plt.subplot2grid((30,44),(27,21),rowspan=1, colspan=6)
ax_rclr = plt.subplot2grid((10,22),(0,14),rowspan=8, colspan=4)
ax_rclr_colbar = plt.subplot2grid((30,44),(27,29),rowspan=1, colspan=6)
ax_da = plt.subplot2grid((10,22),(0,18),rowspan=8, colspan=3)
ax_da_colbar = plt.subplot2grid((30,44),(27,37),rowspan=1, colspan=4)

ft_ra = pd.read_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_ra_red_ITS.csv', index_col=0, header=0)
ft_ra['Taxonomy'] = ''
for row in ft_ra.index:
  this_tax = full_tax[row]
  if 's__' in this_tax[-1]: this_tax = this_tax[:-1]
  this_tax = ';'.join(list(this_tax))
  ft_ra.loc[row, 'Taxonomy'] = this_tax
ft_ra = ft_ra.sort_values(by=['Taxonomy'], ascending=False)
ft_tax = ft_ra.loc[:, ['Taxonomy']]
ft_ra = ft_ra.drop('Taxonomy', axis=1)
order = list(ft_ra.index.values)

handles = []
prev_class, start, class_count = '', -0.5, 12
for g in range(len(ft_tax.index.values)):
  gen = ft_tax.index[g]
  if g == len(ft_tax.index.values)-1: end = True
  else: end = False
  this_clss = ft_tax.loc[gen, 'Taxonomy'].split('; ')
  #this_clss = this_clss[1].replace('p__', '')+' '+this_clss[2].replace('c__', '')
  this_clss = this_clss[2].replace('c__', '')
  if prev_class == '':
    prev_class = this_clss
    continue
  if prev_class != this_clss or end:
    if end: length = g+0.5-start
    else: length = g-0.5-start
    bar = ax_class.bar(0, length, bottom=start, edgecolor='k', alpha=0.4)
    bar2 = ax_tree.bar(0, length, bottom=start, alpha=0.15, width=3)
    text = ax_class.text(0, start+(length/2), str(class_count), ha='center', va='center')
    color = bar.patches[0].get_facecolor()
    handles.append(Patch(facecolor=color, edgecolor='k', label=str(class_count)+': '+prev_class))
    start = g-0.5
    class_count -= 1
  prev_class = this_clss
handles.reverse()
lg = ax_class.legend(handles=handles, loc='upper left', bbox_to_anchor=(0, -0.01), ncol=1)
plt.sca(ax_tree)
yl = plt.ylim([-0.5, 43.5])
yl = plt.yticks([])
xl = plt.xticks([])
xl = plt.xlim([0,1])
plt.sca(ax_class)
yl = plt.ylim([-0.5, 43.5])
yl = plt.yticks([])
xl = plt.xticks([])

ft_ra = ft_ra.loc[order, :].rename(columns=samples_treat_loc_only)
treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
ft_ra = ft_ra.groupby(by=ft_ra.columns, axis=1).mean().loc[:, treat_order]
ft_ra_norm = ft_ra.copy(deep=True).transpose()
ft_ra_norm = ft_ra_norm.divide(ft_ra_norm.max(axis=0), axis=1).transpose()
plt.sca(ax_ra)
pc = plt.pcolor(ft_ra_norm, cmap='RdPu', edgecolor='k')
yt = plt.yticks([])
genus_names = list(ft_ra.index.values)
for g in range(len(genus_names)):
  this_genus = genus_names[g]
  if 'g__' in this_genus: this_genus = '$'+this_genus.replace('g__', '')+'$ '
  genus_names[g] = this_genus
yt = plt.yticks([a+0.5 for a in range(len(ft_ra.index))], [i+'  ' for i in genus_names])
for r in range(len(ft_ra.index)):
  for c in range(len(ft_ra.columns)):
    row, col = ft_ra.index[r], ft_ra.columns[c]
    if ft_ra_norm.loc[row, col] > 0.5: color = 'w'
    else: color = 'k'
    tx = ax_ra.text(c+0.5, r+0.5, str(round(ft_ra.loc[row, col], 2)), color=color, ha='center', va='center')
xt = plt.xticks([a+0.5 for a in range(len(ft_ra.columns))], [c.replace(' Control', '\nControl').replace(' Treatment', '\nTreatment') for c in ft_ra.columns], rotation=90)
#tt = ax_ra.xaxis.tick_top()
ti = ax_ra.set_title('Relative\nabundance (%)', fontweight='bold')
ti = ax_ra.set_title('A', loc='left', fontweight='bold', fontsize=16)

plt.sca(ax_ra_colbar)
cmap = mpl.cm.RdPu
norm = mpl.colors.Normalize(vmin=0, vmax=1)
cb = mpl.colorbar.ColorbarBase(ax_ra_colbar, cmap=cmap, norm=norm, orientation='horizontal')
xl = plt.title('Proportion of maximum\nfor genus', fontweight='bold')
    
ft_rclr = pd.read_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_rclr_red_ITS.csv', index_col=0, header=0)
ft_rclr = ft_rclr.loc[order, :].rename(columns=samples_treat_loc_only)
treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
ft_rclr = ft_rclr.groupby(by=ft_rclr.columns, axis=1).mean().loc[:, treat_order]
plt.sca(ax_rclr)
pc = plt.pcolor(ft_rclr, cmap='bwr', edgecolor='k', vmin=-2, vmax=2)
yt = plt.yticks([])
for r in range(len(ft_rclr.index)):
  for c in range(len(ft_rclr.columns)):
    row, col = ft_rclr.index[r], ft_rclr.columns[c]
    if abs(ft_rclr.loc[row, col]) > 1: color = 'w'
    else: color = 'k'
    tx = ax_rclr.text(c+0.5, r+0.5, str(round(ft_rclr.loc[row, col], 2)), color=color, ha='center', va='center')
xt = plt.xticks([a+0.5 for a in range(len(ft_rclr.columns))], [c.replace(' Control', '\nControl').replace(' Treatment', '\nTreatment') for c in ft_rclr.columns], rotation=90)
#tt = ax_rclr.xaxis.tick_top()
ti = ax_rclr.set_title('rCLR relative\nabundance', fontweight='bold')
ti = ax_rclr.set_title('B', loc='left', fontweight='bold', fontsize=16)

plt.sca(ax_rclr_colbar)
cmap = mpl.cm.bwr
norm = mpl.colors.Normalize(vmin=-2, vmax=2)
cb = mpl.colorbar.ColorbarBase(ax_rclr_colbar, cmap=cmap, norm=norm, orientation='horizontal')
xl = plt.title('rCLR relative\nabundance', fontweight='bold')

da_int_folder = folder+'robyn_analysis/differential_abundance_intermediate_mag/'
all_da = pd.read_csv(da_int_folder+'all_da_ITS.csv', index_col=0, header=0)
all_da = all_da.loc[order, ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']]
plt.sca(ax_da)
pc = plt.pcolor(all_da, cmap='Blues', edgecolor='k', vmin=0, vmax=3)
ti = ax_da.set_title('Differential\nabundance', fontweight='bold')
ti = ax_da.set_title('C', loc='left', fontweight='bold', fontsize=16)
yt = plt.yticks([])
xt = plt.xticks([a+0.5 for a in range(len(all_da.columns))], [c+'\nControl $vs$\nTreatment' for c in all_da.columns], rotation=90)
da_tests = [pd.read_csv(da_int_folder+'ancom_ITS.csv', index_col=0, header=0), pd.read_csv(da_int_folder+'aldex_ITS.csv', index_col=0, header=0), pd.read_csv(da_int_folder+'maaslin_ITS.csv', index_col=0, header=0)]
x_loc, markers = [-0.25, 0, 0.25], ['o', 's', '^']
for r in range(len(all_da.index)):
  for c in range(len(all_da.columns)):
    row, col = all_da.index[r], all_da.columns[c]
    if all_da.loc[row, col] == 0: continue
    if all_da.loc[row, col] > 1: color = 'w'
    else: color = 'k'
    for t in range(len(da_tests)):
      if row not in da_tests[t].index: continue
      if da_tests[t].loc[row, col] > 0: 
        sc = ax_da.scatter(c+0.5+x_loc[t], r+0.5, marker=markers[t], color=color)

plt.sca(ax_da_colbar)
cmap_da = 'Blues'
norm = mpl.colors.Normalize(vmin=0, vmax=3)
fake_df = pd.DataFrame([[0, 1, 2, 3]])
pc = plt.pcolor(fake_df, edgecolor='k', cmap=cmap_da, vmin=0, vmax=3)
yt = plt.yticks([])
xt = plt.xticks([0.5, 1.5, 2.5, 3.5], [0, 1, 2, 3])
xl = plt.title('Number of tools finding\ngenus DA', fontweight='bold')

tests = ['ANCOM-II', 'ALDEx2', 'MaAsLin2']
handles = [Line2D([0], [0], marker=markers[m], color='w', label=tests[m], markerfacecolor='k', markersize=8) for m in range(len(markers))]
plt.sca(ax_da_colbar)
lg = plt.legend(handles=handles, loc='upper center', bbox_to_anchor=(0.5, -1), ncol=2)

#plt.show()
plt.subplots_adjust(hspace=0.7)
plt.savefig(folder+'robyn_analysis/figures_mag/tree_heatmap_ITS.png', dpi=600, bbox_inches='tight')
```

Now make boxplots with the top taxa:
```{python}
top_taxa = pd.read_csv(folder+'robyn_analysis/differential_abundance_intermediate_mag/ft_ra_red_ITS.csv', index_col=0, header=0).index.values
ft_ra = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_relabun_ITS.csv', index_col=0, header=0)
ft_ra = ft_ra.rename(columns=sample_new, index=genus_match)
ft_ra = ft_ra.groupby(by=ft_ra.index, axis=0).sum()

ft_rclr = pd.read_csv(folder+'robyn_analysis/tables_convert_from_maggie/ft_rclr_ITS.csv', index_col=0, header=0)
ft_rclr = ft_rclr.rename(columns=sample_new, index=genus_match)
ft_rclr = ft_rclr.groupby(by=ft_rclr.index, axis=0).sum()

treat_order = ['Upper Forest Floor Control', 'Upper Forest Floor Treatment', 'Lower Forest Floor Control', 'Lower Forest Floor Treatment', 'Upper B Horizon Control', 'Upper B Horizon Treatment']
#treat_order = ['Control Upper Forest Floor', 'Treatment Upper Forest Floor', 'Control Lower Forest Floor', 'Treatment Lower Forest Floor', 'Control Upper B Horizon', 'Treatment Upper B Horizon']
color_dict = {'Control':'#16A085', 'Treatment':'#F1C40F', 'Upper Forest Floor':'#E74C3C', 'Lower Forest Floor':'#8E44AD', 'Upper B Horizon':'#3498DB'}
x_loc = [0, 1, 2.5, 3.5, 5, 6]
x_labs = ['Control', 'Treatment', 'Control', 'Treatment', 'Control', 'Treatment']
x_loc_hor = [0.15, 0.5, 0.85]
x_lab_hor = ['Upper Forest Floor', 'Lower Forest Floor', 'Upper B Horizon']

count = 0
for tax in top_taxa:
  #if tax != 'g__Gemmatimonas': continue
  fig = plt.figure(figsize=(12,7))
  ti = fig.suptitle(tax.replace('g__', ''), fontweight='bold')
  ax1, ax2 = plt.subplot(121), plt.subplot(122)
  axes, fts, titles = [ax1, ax2], [ft_ra, ft_rclr], ['Relative abundance (%)', 'rCLR relative abundance']
  for a in range(len(axes)):
    plt.sca(axes[a])
    if a == 1: li = axes[a].plot([-0.5, 6.5], [0, 0], 'k--')
    xl = plt.xlim([-0.5, 6.5])
    for b in range(len(treat_order)):
      vals = fts[a].loc[tax, treat_order[b]].values
      if 'Control' in treat_order[b]: color = color_dict['Control']
      else: color = color_dict['Treatment']
      sc = axes[a].scatter(np.random.normal(x_loc[b], 0.1, len(vals)), vals, color=color)
      box = axes[a].boxplot(vals, positions=[x_loc[b]], widths=0.6, showfliers=False)
      for item in ['boxes', 'whiskers', 'fliers', 'medians', 'caps']: bi = plt.setp(box[item], color='k')
      ti = axes[a].set_title(titles[a])
      if a == 0: yl = axes[a].set_ylabel('Abundance')
      ti = plt.xticks(x_loc, x_labs, rotation=90)
      for c in range(len(x_loc_hor)):
        tx = axes[a].text(x_loc_hor[c], -0.2, x_lab_hor[c], ha='center', va='center', transform=axes[a].transAxes)
  plt.savefig('/Users/maggiehosmer/Library/CloudStorage/OneDrive-DalhousieUniversity/Acid_Rain_Project/March_23/robyn_analysis/figures_mag/boxplots_ITS/ITS_taxa_'+str(count+1)+'_'+tax+'.png', dpi=600, bbox_inches='tight')
  count += 1
  
finished = True
```